[["index.html", "STAT 615 Note Book Chapter 1 About 1.1 Usage 1.2 Render book 1.3 Preview book", " STAT 615 Note Book Peter Wang 2023-04-30 Chapter 1 About 1.1 Usage Each bookdown chapter is an .Rmd file, and each .Rmd file can contain one (and only one) chapter. A chapter must start with a first-level heading: # A good chapter, and can contain one (and only one) first-level heading. Use second-level and higher headings within chapters like: ## A short section or ### An even shorter section. The index.Rmd file is required, and is also your first book chapter. It will be the homepage when you render the book. 1.2 Render book You can render the HTML version of this example book without changing anything: Find the Build pane in the RStudio IDE, and Click on Build Book, then select your output format, or select “All formats” if you’d like to use multiple formats from the same book source files. Or build the book from the R console: bookdown::render_book() To render this example to PDF as a bookdown::pdf_book, you’ll need to install XeLaTeX. You are recommended to install TinyTeX (which includes XeLaTeX): https://yihui.org/tinytex/. 1.3 Preview book As you work, you may start a local server to live preview this HTML book. This preview will update as you edit the book when you save individual .Rmd files. You can start the server in a work session by using the RStudio add-in “Preview book”, or from the R console: bookdown::serve_book() "],["classification-problem-bayes-classifier.html", "Chapter 2 Classification Problem &amp; Bayes Classifier 2.1 Notation 2.2 Classification Problem 2.3 Other Topics", " Chapter 2 Classification Problem &amp; Bayes Classifier 2.1 Notation \\(\\mathcal X\\) = input space; \\(\\mathcal Y\\) = output space \\(x\\) = feature vector, input, data point; \\(y\\) = label \\((X, Y)\\) = random variable. Supervised Learning: From given data set \\((x_1,y_1), \\cdots, (x_n,y_n)\\), find \\(\\mathfrak f\\), such that \\(\\mathfrak f: ~x (\\in \\mathcal X) \\to y (\\in \\mathcal Y)\\). \\((x_1,y_1), \\cdots, (x_n,y_n)\\) come from a distribution of input-output pairs. Distribution: \\(\\rho\\), is a probability distribution over \\(\\mathcal X \\times \\mathcal Y\\), the “Ground Truth”. 2.2 Classification Problem Given \\(\\mathfrak f : \\mathcal X \\to \\mathcal Y\\), compute \\(P_{(X,Y) \\sim \\rho}(\\mathfrak f(X) \\neq Y)\\), which is average misclassification error (AME). 2.2.1 Goal To build the “best” possible classifier, that is find \\(\\mathfrak f\\) that makes the AME as small as possible. 2.2.2 Questions Does there exist a “best” classifier (relative to AME)? Theorem 2.1 (Bayes Classifier) Given \\(\\rho\\) distribution over \\(\\mathcal X \\times \\mathcal Y\\), \\(l\\) = 0-1 loss; \\(\\mathcal Y\\) = {0,1} (binary problem); \\(\\mathfrak f_B(x)\\) := \\(\\begin{cases}1 &amp; if ~P_{(X,Y) \\in \\rho}(Y=1 \\mid X=x) \\geq P_{(X,Y) \\in \\rho}(Y=0 \\mid X=x)\\\\0 &amp; o.w.\\end{cases}\\). Then \\(\\mathfrak f_B\\) minimizes the AME. Proof. \\(\\forall ~\\mathfrak f: \\mathcal X \\to \\{0,1\\}\\), we have \\[ \\begin{aligned} P(\\mathfrak f(X) \\neq Y) &amp;= E[1_{\\mathfrak f(X) \\neq Y}]\\\\ &amp;= E\\Big[E[1_{\\mathfrak f(X) \\neq Y} \\mid X]\\Big]\\\\ &amp;= E\\Big[1_{\\mathfrak f(X) \\neq 1} \\cdot P(Y=1 \\mid X) + 1_{\\mathfrak f(X) \\neq 0} \\cdot P(Y=0 \\mid X)\\Big]\\\\ \\end{aligned} \\] When \\(P(Y=1 \\mid X) \\geq P(Y=0 \\mid X)\\), we have \\[ \\begin{aligned} 1_{\\mathfrak f(X) \\neq 1} \\cdot P(Y=1 \\mid X) + 1_{\\mathfrak f(X) \\neq 0} \\cdot P(Y=0 \\mid X) &amp;\\geq 1_{\\mathfrak f(X) \\neq 1} \\cdot P(Y=0 \\mid X) + 1_{\\mathfrak f(X) \\neq 0} \\cdot P(Y=0 \\mid X)\\\\ &amp;= P(Y=0 \\mid X) \\cdot (1_{\\mathfrak f(X) \\neq 1} + 1_{\\mathfrak f(X) \\neq 0})\\\\ &amp;= P(Y=0 \\mid X)\\\\ &amp;=_{\\mathfrak f_B(X) = 1} ~P(\\mathfrak f_B(X) \\neq Y \\mid X) \\end{aligned} \\] When \\(P(Y=0 \\mid X) &gt; P(Y=1 \\mid X)\\), we similarly have \\[ \\begin{aligned} 1_{\\mathfrak f(X) \\neq 1} \\cdot P(Y=1 \\mid X) + 1_{\\mathfrak f(X) \\neq 0} \\cdot P(Y=0 \\mid X) &gt; P(\\mathfrak f_B(X) \\neq Y \\mid X) \\end{aligned} \\] As a result, we have \\[ \\begin{aligned} P(\\mathfrak f(X) \\neq Y) &amp;\\geq E[P(\\mathfrak f_B(X) \\neq Y \\mid X)]\\\\ &amp;= E\\Big[E[1_{\\mathfrak f_B(X) \\neq Y} \\mid X]\\Big]\\\\ &amp;= P(\\mathfrak f_B(X) \\neq Y) \\end{aligned} \\] which means that \\(\\mathfrak f_B\\) minimizes the AME. Can we construct this “best” classifier (if we only observe the data \\((x_1, y_1), \\cdots, (x_n, y_n)\\))? If we can not build this classifier from the observed data, then what can we do in that case? 2.2.3 The 0-1 Loss \\[\\begin{aligned}l:\\{1, \\cdots, k\\} \\times \\{1, \\cdots, k\\} &amp;\\to \\mathcal R\\\\(\\mathcal Y, \\mathcal Y&#39;) &amp;\\to \\mathcal R\\end{aligned}; \\quad l(y,y&#39;) = \\begin{cases}1 &amp; if ~y\\neq y&#39;\\\\0 &amp; if ~y = y&#39;\\end{cases}.\\] Relative to this loss function, and relative to the distribution \\(\\rho\\), we can define the risk of a given classifier \\(\\mathfrak f: \\mathcal X \\to \\mathcal Y = \\{1, \\cdots, k\\}\\), \\[ \\begin{aligned} R(\\mathfrak f) :&amp;= E_{(X, Y) \\in \\rho}[l(\\mathfrak f(X), Y)] \\\\ &amp;= P(\\mathfrak f(X) \\neq Y). \\end{aligned} \\] To find the “best” classifier is to solve \\(min_{\\mathfrak f} R(\\mathfrak f)\\). Example 2.1 \\(y_1\\) = stop sign, \\(y_2\\) = 50 mph, \\(y_3\\) = 40 mph. The classifier classifies \\(\\mathfrak f: x \\to y_2\\), when \\((x,y)\\) was such that \\(y\\) = stop sign. Then the 0-1 loss is \\(l(\\mathfrak f(x), y) = l(y_2, y_1) = 1\\). Predicting 50 mph, when \\(y\\) = stop sign seems to be worse than predicting 40 mph, when \\(y\\) = 50 mph. Thus other loss function may be better. 2.2.4 Observations \\(\\mathfrak f_B\\) depends on \\(\\rho\\): if \\((X,Y) \\sim \\rho&#39;\\), you can not expect \\(\\mathfrak f_B\\) constructed from \\(\\rho\\) to do well at classifying \\((X,Y)\\). Bayes Rule: \\[ P(Y=1 \\mid X=x) = \\frac{\\rho_{X\\mid Y=1}(x) \\cdot P(Y=1)}{\\rho_X(x)} \\] Thus, \\[\\begin{aligned}P(Y=1 \\mid X=x) \\geq P(Y=0 \\mid X=x) &amp;\\Leftrightarrow \\rho_{X\\mid Y=1}(x) \\cdot P(Y=1) \\geq \\rho_{X\\mid Y=0}(x) \\cdot P(Y=0)\\\\ &amp;\\Leftrightarrow P(X=x, Y=1) \\geq P(X=x, Y=0)\\\\ &amp;(\\text{useful when the input space } \\mathcal X \\text{ is discrete}) \\end{aligned} \\] In general there are multiple solutions to the problem. However, all of them have the form of \\(\\mathfrak f_B\\). \\(R^*_B = min_{\\mathfrak f} ~P(\\mathfrak f(X) \\neq Y) = P(\\mathfrak f_B(X) \\neq Y)\\) is Bayes Risk, which indicates how accurate the classifier is. Notice that regardless of what \\(\\rho\\) is, \\(R^*_B \\leq \\frac{1}{2}\\). Both \\(\\mathfrak f_B\\) and \\(R^*_B\\) depend on \\(\\rho\\). But also if we were to change the loss function, the formula for \\(\\mathfrak f_B\\) and the value of \\(R^*_B\\) would change. 2.2.5 Examples Example 2.2 \\(\\mathcal X = \\{a,b,c,d,e,f\\};~ \\mathcal Y = \\{0,1\\};~ \\rho\\) is a distribution over \\(\\mathcal X \\times \\mathcal Y\\). a b c d e f 0 0.1 0.2 0.5 0.3 0.8 0.9 1 0.9 0.3 0.1 0.3 0.1 0.3 \\(P(X=x, Y=y) = \\frac{q(x,y)}{M}\\), where \\(q(\\cdot, \\cdot)\\) is element of the above matrix, and \\(M\\) is the normalization constant. According to the Bayes Rule, we have: \\[ \\begin{aligned} \\mathfrak f_B(x) &amp;= \\begin{cases} 1 &amp; if ~ P(X=x, Y=1) \\geq P(X=x, Y=0)\\\\ 0 &amp; o.w. \\end{cases}\\\\ &amp;= \\begin{cases} 1 &amp;if ~ q(x,1) \\geq q(x,0)\\\\ 0 &amp; o.w. \\end{cases} \\end{aligned} \\] Thus, a b c d e f \\(\\mathfrak f_B\\) 1 1 0 1 (0 is also OK) 0 0 Example 2.3 (Mixture of Gaussians Model) \\(\\mathcal X = \\mathcal R\\); \\(\\mathcal Y = \\{0,1\\}\\); \\((X, Y) \\sim \\rho\\), \\(P(Y=1) = \\omega_1\\), \\(P(Y=0) = \\omega_0\\); \\(X \\mid Y=1 \\sim N(\\mu_1, \\sigma_1^2)\\), \\(X \\mid Y=0 \\sim N(\\mu_0, \\sigma_0^2)\\). According to the Bayes Rule, we have: \\[ \\begin{aligned} P(Y=1 \\mid X=x) \\geq P(Y=0 \\mid X=x) &amp;\\Leftrightarrow \\frac{\\rho_1(x) \\cdot P(Y=1)}{\\rho(x)} \\geq \\frac{\\rho_0(x) \\cdot P(Y=0)}{\\rho(x)}\\\\ &amp;\\Leftrightarrow \\rho_1(x) \\cdot \\omega_1 \\geq \\rho_0(x) \\cdot \\omega_0\\\\ &amp;\\Leftrightarrow \\omega_1 \\cdot \\frac{1}{\\sqrt{2\\pi}\\sigma_1} ~exp[-\\frac{(x-\\mu_1)^2}{2\\sigma_1^2}] \\geq \\omega_0 \\cdot \\frac{1}{\\sqrt{2\\pi}\\sigma_0} ~exp[-\\frac{(x-\\mu_0)^2}{2\\sigma_0^2}]\\\\ &amp;\\Leftrightarrow log(\\frac{\\omega_1}{\\sigma_1}) - \\frac{(x-\\mu_1)^2}{2\\sigma_1^2} \\geq log(\\frac{\\omega_0}{\\sigma_0}) - \\frac{(x-\\mu_0)^2}{2\\sigma_0^2} \\end{aligned} \\] where \\(\\rho_1(x) = P(X=x \\mid Y=1)\\), \\(\\rho_0(x) = P(X=x \\mid Y=0)\\), \\(\\rho(\\cdot)\\) is the marginal density of \\(X\\). 2.3 Other Topics “Weak Classifier” or “Probabilistic Classifier” \\(\\mathfrak g: \\mathcal X \\to [0,1]\\). \\(\\mathfrak g(x)\\) = likelihood that we are going to label 1. \\(min_{\\mathfrak g} ~E[\\mid \\mathfrak g(x) - Y \\mid]\\). Theorem 2.2 …… "],["plug-in-classifiers-similarity-classifier.html", "Chapter 3 Plug-in Classifiers (Similarity Classifier) 3.1 Notions of Consistency for Families of Binary Classifier 3.2 Functions of \\(\\hat{\\eta}_n\\) 3.3 Consistency 3.4 Strong Consistency", " Chapter 3 Plug-in Classifiers (Similarity Classifier) For binary classification with 0-1 loss: \\(\\mathfrak f_B(x)\\) = \\(\\begin{cases}1 &amp; if ~P_{(X,Y) \\in \\rho}(Y=1 \\mid X=x) \\geq P_{(X,Y) \\in \\rho}(Y=0 \\mid X=x)\\\\0 &amp; o.w.\\end{cases}\\) is Motivate “plug-in” or similarity classifier; \\(\\mathfrak f_B \\in \\underset{\\mathfrak f: \\mathcal X \\to \\{0,1\\}}{\\operatorname{argmin}} ~ P(\\mathfrak f(X) \\neq Y)\\) is Motivate ERM (Empirical Risk Minimization). For this chapter, we will talk about the first one. Define \\(\\eta(x) := P(Y=1 \\mid X=x)\\), then we can rewrite \\(\\mathfrak f_B(x)\\) as: \\(\\mathfrak f_B(x) = \\begin{cases}1 &amp; \\eta(x) \\geq \\frac{1}{2}\\\\0 &amp; o.w.\\end{cases}.\\) Idea: Replace \\(\\eta(x)\\) with \\(\\hat \\eta_n(x)\\) that is built from our training data \\((x_1,y_1), \\cdots, (x_n,y_n)\\): \\(\\hat{\\mathfrak f}_n(x) = \\begin{cases}1 &amp; \\hat \\eta_n(x) \\geq \\frac{1}{2}\\\\0 &amp; o.w.\\end{cases}.\\) Lemma 3.1 Let \\(\\mathfrak f\\) be an arbitrary binary classifier. Then \\[ 0 \\leq R(\\mathfrak f) - R_B^* = E\\Big[\\mid 2 \\eta(X) - 1 \\mid \\cdot 1_{\\mathfrak f(X) \\neq \\mathfrak f_B(X)}\\Big] \\leq 2 E\\Big[ \\mid \\eta(X) - \\alpha(X) \\mid \\Big], \\] where we suppose \\(\\mathfrak f(X) = \\begin{cases}1 &amp; \\alpha(X) \\geq \\frac{1}{2}\\\\0 &amp; o.w.\\end{cases}.\\) Proof. As \\[ \\begin{aligned} E[1_{\\mathfrak f(X) \\neq Y} - 1_{\\mathfrak f_B(X) \\neq Y} \\mid X] &amp;= (1_{\\mathfrak f(X) \\neq 1} - 1_{\\mathfrak f _B(X) \\neq 1}) \\cdot P(Y=1 \\mid X) + (1_{\\mathfrak f(X) \\neq 0} - 1_{\\mathfrak f _B(X) \\neq 0}) \\cdot P(Y=0 \\mid X)\\\\ &amp;= (1_{\\mathfrak f(X) \\neq 1} - 1_{\\mathfrak f _B(X) \\neq 1}) \\cdot \\eta(X) + (1_{\\mathfrak f(X) \\neq 0} - 1_{\\mathfrak f _B(X) \\neq 0}) \\cdot (1-\\eta(X))\\\\ &amp;= \\begin{cases} 0 &amp; if ~ \\mathfrak f(X) = \\mathfrak f_B(X) = 1\\\\ 0 &amp; if ~ \\mathfrak f(X) = \\mathfrak f_B(X) = 0\\\\ \\mid 1-2\\eta(X) \\mid &amp; if ~ \\mathfrak f(X) =1,~ \\mathfrak f_B(X) = 0\\\\ \\mid 2\\eta(X)-1 \\mid &amp; if ~ \\mathfrak f(X) =0,~ \\mathfrak f_B(X) = 1\\\\ \\end{cases}\\\\ &amp;= \\mid 2\\eta(X)-1 \\mid \\cdot 1_{\\mathfrak f(X) \\neq \\mathfrak f_B(X)}, \\end{aligned} \\] we have: \\[ \\begin{aligned} R(\\mathfrak f) - R_B^* &amp;= E\\Big[E[1_{\\mathfrak f(X) \\neq Y} - 1_{\\mathfrak f_B(X) \\neq Y} \\mid X] \\Big]\\\\ &amp;= E\\Big[\\mid 2 \\eta(X) - 1 \\mid \\cdot 1_{\\mathfrak f(X) \\neq \\mathfrak f_B(X)}\\Big]. \\end{aligned} \\] Moreover, Case1: \\(\\mathfrak f(X) \\neq \\mathfrak f_B(X)\\), \\(\\eta(X) &lt; \\frac{1}{2}\\) In this case, \\(\\mathfrak f_B(X) = 0\\) and \\(\\mathfrak f(X) = 1\\), which means that \\(\\alpha(X) \\geq \\frac{1}{2}\\). So, \\(2 \\mid \\eta(X) - \\frac{1}{2} \\mid \\leq 2 \\mid \\eta(X) - \\alpha(X) \\mid\\). Case 2: \\(\\mathfrak f(X) \\neq \\mathfrak f_B(X)\\), \\(\\eta(X) \\geq \\frac{1}{2}\\) Similarly, we have \\(2 \\mid \\frac{1}{2} - \\eta(X) \\mid \\leq 2 \\mid \\eta(X) - \\alpha(X) \\mid\\). Thus, \\(E\\Big[\\mid 2 \\eta(X) - 1 \\mid \\cdot 1_{\\mathfrak f(X) \\neq \\mathfrak f_B(X)}\\Big] \\leq 2E\\Big[\\mid \\eta(X) -\\alpha(X) \\mid \\cdot 1_{\\mathfrak f(X) \\neq \\mathfrak f_B(X)}\\Big].\\) Corollary 3.1 If \\(\\hat{\\mathfrak f}_n(X) = \\begin{cases}1&amp; if~ \\hat \\eta_n(X) \\geq 1/2 \\\\0 &amp; o.w.\\end{cases}\\), \\(\\hat \\eta_n(X) = \\hat \\eta_n (X; (x_1, y_1), \\cdots, (x_n, y_n))\\), then \\[ E[R(\\hat{\\mathfrak f}_n)] - R^*_B \\leq 2 E\\Big[\\mid \\eta(X) - \\hat \\eta_n(X) \\mid\\Big]. \\] Remark. For \\(\\hat{\\mathfrak f}_n\\), \\(\\eta(X)\\), and \\(\\hat \\eta_n(X)\\), we have \\((X, Y) \\sim \\rho\\) and \\((x_1, y_1), \\cdots, (x_n, y_n) \\sim \\rho\\). Proof. Given \\((x_1, y_1), \\cdots, (x_n, y_n)\\), according to Lemma 3.1, we have: \\(R(\\hat{\\mathfrak f}_n) - R^*_B \\leq 2 E\\Big[\\mid \\eta(X) - \\hat \\eta_n(X) \\mid\\Big]\\). In general, we are interested in building classifier from observation \\((x_1, y_1), \\cdots, (x_n, y_n)\\): \\(\\hat {\\mathfrak f}_n: ~\\mathcal X \\to \\{0,1\\}\\), \\(\\hat {\\mathfrak f}_n (X) \\in \\{0,1\\}\\). Example 3.1 (Dependency on Data) Given \\((x_1, y_1), \\cdots, (x_n, y_n)\\), \\[ \\hat \\eta_n(X) := \\frac{\\sum_{i=1}^n Y_i exp(-\\mid X_i - X \\mid ^2 / r_n^2)}{\\sum_{i=1}^n exp(-\\mid X_i - X \\mid ^2 / r_n^2)}. \\] Then we have: \\[ \\hat {\\mathfrak f}_n(X; (x_1, y_1), \\cdots, (x_n, y_n)) = \\begin{cases} 1 &amp; if ~\\hat \\eta_n(X) \\geq \\frac{1}{2}\\\\ 0 &amp; o.w. \\end{cases} \\] Remark. \\(\\hat \\eta_n(X) \\in [0,1]\\). Goal: To build \\(\\hat{\\mathfrak f}_n\\) in such a way that \\(R(\\hat{\\mathfrak f}_n) - R^*_B\\) goes to 0 as \\(n \\to \\infty\\). 3.1 Notions of Consistency for Families of Binary Classifier We say that \\(\\{\\hat{\\mathfrak f}_n\\}_{n\\in N}\\) is consistent for the distribution \\(\\rho\\), if we have: \\[ \\underset{n \\to \\infty}{\\operatorname{lim}} (E_{(x_1, y_1), \\cdots, (x_n, y_n)} [R(\\hat{\\mathfrak f}_n)] - R^*_B) = 0 \\] Remark. \\((x_1, y_1), \\cdots, (x_n, y_n) \\underset{i.i.d}{\\sim} \\rho\\). \\(R^*_B = \\underset{\\mathfrak f}{\\operatorname{min}} P_{(X,Y) \\sim \\rho} [\\mathfrak f(X) \\neq Y]\\). \\(R(\\hat{\\mathfrak f}_n) = P_{(X,Y) \\sim \\rho} [\\hat{\\mathfrak f}_n(X) \\neq Y]\\). We say that \\(\\{\\hat{\\mathfrak f}_n\\}_{n\\in N}\\) is strongly consistent for the distribution \\(\\rho\\), if we have: \\[ \\underset{n \\to \\infty}{\\operatorname{lim}} (R(\\hat{\\mathfrak f}_n) - R^*_B) = 0, ~\\text{with probability 1 (almost sure convergence).} \\] Example 3.2 (Conceptual Explaination) Assume we have M students.Then for student m, we have: \\[ \\begin{cases} (x_1^m, y_1^m), \\cdots, (x_n^m, y_n^m) \\underset{i.i.d}{\\sim} \\rho\\\\ \\text{The plug-in classifier}: ~\\hat{\\mathfrak f}_n^m (\\cdot ~;(x_1^m, y_1^m), \\cdots, (x_n^m, y_n^m))\\\\ \\text{Risk: }R(\\hat{\\mathfrak f}_n^m) = P_{(X,Y) \\sim \\rho} [\\hat{\\mathfrak f}_n^m(X) \\neq Y] \\end{cases}. \\] Q1 (Consistency): Suppose I collect all risks that the class computed: \\(R(\\hat{\\mathfrak f}_n^1), \\cdots, R(\\hat{\\mathfrak f}_n^M)\\), and suppose I average them: \\(\\frac{1}{M} \\sum_{m=1}^M R(\\hat{\\mathfrak f}_n^m) \\approx E_{(x_1, y_1), \\cdots, (x_n, y_n)} [R(\\hat{\\mathfrak f}_n)]\\). Is it true that as \\(n \\to \\infty\\), this average risk goes to \\(R^*_B\\). Q2 (Strong Consistency): Is it true that for each \\(m\\), we have that \\(R(\\hat{\\mathfrak f}_n)\\) converges to \\(R^*_B\\) as \\(n \\to \\infty\\). We say that a family \\(\\{\\hat{\\mathfrak f}_n\\}_n\\) is universal (strong) consistent if \\(\\{\\hat{\\mathfrak f}_n\\}_n\\) is (strong) consistent for all \\(\\rho\\). Example 3.3 (Universality in Statistical Inference) Let \\(\\mu\\) be a probability distribution over \\(R\\) with well defined first moment \\(\\theta := E_{Z \\sim \\mu} (Z)\\). The goal is to build an estimator \\(\\hat \\theta_n(z_1, \\cdots, z_n)\\) that is consistent for \\(\\theta\\). \\(\\hat \\theta_n^1(z_1, \\cdots, z_n) = \\frac{1}{n} \\sum z_i ~(\\text{Sample Mean})\\), is universal strong consistent. \\(z_1, \\cdots, z_n \\underset{i.i.d}{\\sim} \\mu\\) for arbitrary \\(\\mu\\), by Law of Large Number (Strong LLN), we know that with probability 1, \\((\\hat \\theta_n^1(z_1, \\cdots, z_n) - \\theta) \\to 0\\) as \\(n \\to \\infty\\). \\(\\hat \\theta_n^2(z_1, \\cdots, z_n) = \\text{Sample Median}\\), is not universal consistent. If \\(\\mu\\) is a distribution such that its median is not equal to its mean, then it is not true that \\((\\hat \\theta_n^2(z_1, \\cdots, z_n) - \\theta) \\to 0\\) as \\(n \\to \\infty\\). However, \\(\\hat \\theta_n^2(z_1, \\cdots, z_n)\\) is consistent for \\(\\mu = N(1,1)\\) whose mean and median are the same. For the plug-in classifiers, studying (strong) consistency reduce to understanding the following two questions: Does \\(E_{(X,Y) \\sim \\rho} \\Big[\\mid \\eta(X) - \\hat \\eta_n(X) \\mid \\Big]\\) converge to 0 as \\(n \\to \\infty\\), with probability 1? If yes, \\(\\{\\hat{\\mathfrak f}_n\\}_n\\) is strong consistent for \\(\\rho\\). Does \\(E_{(x_1,y_1), \\cdots, (x_n,y_n), (X,Y) \\sim \\rho} \\Big[\\mid \\eta(X) - \\hat \\eta_n(X) \\mid \\Big]\\) converge to 0 as \\(n \\to \\infty\\)? If yes, \\(\\{\\hat{\\mathfrak f}_n\\}_n\\) is consistent for \\(\\rho\\). 3.2 Functions of \\(\\hat{\\eta}_n\\) \\[ \\hat \\eta_n(X; (x_1,y_1), \\cdots, (x_n,y_n)) = \\sum_{i=1}^n y_i \\omega_{in} (X; x_1, \\cdots, x_n) \\] where \\(\\omega_{in} (X; x_1, \\cdots, x_n)\\) is weight that we give to each point \\((x_i, y_i)\\) and \\(\\sum_{i=1}^n \\omega_{in} (X; x_1, \\cdots, x_n) = 1\\). In other words, to determine \\(\\hat \\eta_n(X)\\), we consider weighted averages of the labels \\(y_1, \\cdots, y_n\\). Intuitively the \\(i\\)s for which \\(\\omega_{in}\\) are larger should be ones for which \\(x_i\\) is more similar to \\(X\\). Example 3.4 (Kernel-Based Weights) \\(\\mathcal X = R^d\\), select a length-scale \\(r &gt; 0\\). \\[ \\omega_{in}(X; x_1, \\cdots, x_n) = \\frac{exp(- \\frac{|| X_i - X || ^2}{2r^2}) }{\\sum_{i=1}^n exp(-\\frac{|| X_i - X || ^2}{2r^2})}. \\] Points \\(x_i\\) for which \\(|| X - x_i || \\leq r\\) will be give higher weight than points that are such that \\(|| X - x_i || \\geq r\\). Example 3.5 (Histogram-Based Weights) \\(\\mathcal X = R^d\\), select a length-scale \\(h &gt; 0\\). For \\(d=2\\), we have: Introduce pre-weights: Provided there is at least one \\(x_i\\) in the same cell as \\(X\\): \\[ \\tilde \\omega_{in}(X; x_1, \\cdots, x_n) := \\begin{cases} 1 &amp; \\text{if } x_i \\text{ and } X ~\\text{belong to the same cell}\\\\ 0 &amp; o.w. \\end{cases} \\] Otherwise we define: \\[ \\tilde \\omega_{in}(X; x_1, \\cdots, x_n) := \\frac{1}{n} \\] Then we have: \\[ \\omega_{in}(X; x_1, \\cdots, x_n) = \\frac{\\tilde \\omega_{in}(X; x_1, \\cdots, x_n)}{\\sum_{j=1}^n \\tilde \\omega_{jn}(X; x_1, \\cdots, x_n)} \\] Example 3.6 (k-NN Based Weights) \\(k \\in [1,n]\\) \\[ \\tilde \\omega_{in}(X; x_1, \\cdots, x_n) = \\begin{cases} 1 &amp; \\text{if } x_i \\text{ is among the k-closest points to } X\\\\ 0 &amp; o.w. \\end{cases} \\] Then we have: \\[ \\omega_{in}(X; x_1, \\cdots, x_n) = \\frac{\\tilde \\omega_{in}(X; x_1, \\cdots, x_n)}{\\sum_{j=1}^n \\tilde \\omega_{jn}(X; x_1, \\cdots, x_n)} \\] There may be ties, which will be discussed later. 3.3 Consistency Theorem 3.1 (Stone's Theorem) Let \\(\\omega_{in}(X; x_1, \\cdots, x_n)\\) be such that following three conditions hold: \\(\\exists c&gt;0\\) such that \\(\\forall \\text{non-negative function } g: R^d \\to R\\), with \\(E_{(X,y) \\sim \\rho} [g(X)] &lt; \\infty\\): \\(E_{(X, x_1, \\cdots, x_n)} [\\sum_{i=1}^n \\omega_{in} (X) g(x_i)] \\leq c ~E_X [g(X)]\\); \\(\\forall a &gt; 0\\), \\(\\underset{n \\to \\infty}{\\operatorname{lim}} E_{(X, x_1, \\cdots, x_n)} [\\sum_{i=1}^n \\omega_{in}(X) ~1_{|x_i - X| &gt; a}] = 0\\) (weights are only relevant or large for \\(x_i\\) close to \\(X\\)); \\(\\underset{n \\to \\infty}{\\operatorname{lim}} E_{(X, x_1, \\cdots, x_n)} [\\underset{i=1,\\cdots, n}{\\operatorname{max}} \\omega_{in}(X)] = 0\\). Then the family of similarity classifiers \\(\\{\\hat{\\mathfrak f}_n\\}_n\\) induced by these weights is consistent for \\(\\rho\\). Proof. Goal: to show that \\(E_{(X,Y), (x_1,y_1), \\cdots, (x_n, y_n)} [|\\eta(X) - \\hat \\eta_n(X)|] \\to 0\\) as \\(n \\to \\infty\\). Introduce \\(\\bar \\eta_n(X) := \\sum_{i=1}^n \\eta(x_i) \\omega_{in}(X)\\), then \\[ \\begin{aligned} E_{(X,Y), (x_1,y_1), \\cdots, (x_n, y_n)} [|\\eta(X) - \\hat \\eta_n(X)|] &amp;\\leq E_{(X,Y), (x_1,y_1), \\cdots, (x_n, y_n)} [|\\eta(X) - \\bar \\eta_n(X)|] + \\\\ &amp;\\quad E_{(X,Y), (x_1,y_1), \\cdots, (x_n, y_n)} [|\\bar \\eta_n(X) - \\hat \\eta_n(X)|]\\\\ &amp;\\underset{C.S. Ineq}{\\leq} E_{(X,Y), (x_1,y_1), \\cdots, (x_n, y_n)} [|\\eta(X) - \\bar \\eta_n(X)|] \\text{ (&quot;bias term&quot;)}+ \\\\ &amp;\\quad \\Big(E_{(X,Y), (x_1,y_1), \\cdots, (x_n, y_n)} [|\\bar \\eta_n(X) - \\hat \\eta_n(X)|^2]\\Big)^2 \\text{ (&quot;variance term&quot;)} \\end{aligned} \\] Then show both terms \\(\\to 0\\) as \\(n \\to \\infty\\). Remark. \\[ \\begin{aligned} E[\\hat \\eta_n(X) | X, x_1 \\cdots, x_n] &amp;= \\sum_{i=1}^n E[y_i | X, x_1, \\cdots, x_n] ~\\omega_{in}(X)\\\\ &amp;= \\sum_{i=1}^n E[y_i | X, x_1, \\cdots, x_n] ~\\omega_{in}(X)\\\\ &amp;= \\sum_{i=1}^n E[y_i | x_i] ~\\omega_{in}(X)\\\\ &amp;= \\bar \\eta_n(X) \\end{aligned}; \\] To show that the variance term \\(\\to 0\\) as \\(n \\to \\infty\\), we only need to use condition 3 in the Theorem 3.1; To show that the bias term \\(\\to 0\\) as \\(n \\to \\infty\\), we only need to use conditions 1 and 2 in the Theorem 3.1. Example 3.7 (Continuation of Example 3.5) Let \\(h^d = h_n^d\\). If \\(n h_n \\to \\infty\\) as \\(n \\to \\infty\\), and if \\(h_n^d \\to 0\\) as \\(n \\to \\infty\\), then the family of histogram classifiers \\(\\{\\hat {\\mathfrak f}_{n, h_n}\\}_{n \\in N}\\) is universally consistent. Conditions of the Stones Theorem: Technical Assumption. Locality (\\(h = h_n \\to 0\\) as \\(n \\to \\infty\\)). No weight dominates the others. (For every \\(X\\), we should use a growing number of training data points to make a prediction, i.e. the expected number of points in a cell \\(nh_n^d \\to \\infty\\) as \\(n \\to \\infty\\)) For example, let \\(\\rho = Uniform\\), \\(N_X = \\#\\{x_i ~s.t. ~x_i \\in Cell(X)\\}\\), then \\(N_X \\sim Binomial(n, P_h)\\), where \\(P_h = P(x_i \\in Cell(X)) \\propto h^d\\). As a result, \\(E(N_X) \\propto nh^d\\). Example 3.8 (Continuation of Example 3.6) \\(k \\to \\infty\\) (locality) \\(\\frac{k}{n} \\to 0\\) (Related to condition 3 in Stone’s Theorem) 3.4 Strong Consistency 3.4.1 Theorems from probability theory: Theorem 3.2 (Strong Law of Large Numbers) Let \\(Z_1, Z_2, \\cdots\\) be \\(i.i.d\\) real valued random variables, and \\(E(Z_i) = m\\). Then \\(\\frac{1}{n} \\sum_{i=1}^n (Z_i - m) \\to 0\\) almost surely as \\(n \\to \\infty\\). Theorem 3.3 (Central Limit Theorem) (It quantifies in a sense how fast is the convergence in the LLN) Suppose \\(Var(Z_i) = \\sigma^2 &lt; \\infty\\) for \\(\\{Z_i\\}\\) in Theorem 3.2 , then \\(\\sqrt n (\\frac{1}{n} \\sum_{i=1}^n (Z_i - m)) \\underset{d}{\\to} N(0, \\sigma^2)\\). Recall, what this means is that \\(\\forall t\\in R\\), we have: \\[ \\underset{n\\to \\infty}{\\operatorname{lim}} P(\\frac{\\sqrt n}{\\sigma} [\\frac{1}{n}\\sum_{i=1}^n (Z_i - m)] &gt; t) = \\int_t^\\infty \\frac{e^{-s^2/2}}{\\sqrt {2\\pi}} ds = 1-F(t) \\] Remark. CLT is still asymptotic (渐近的). Theorem 3.4 (Berry-Essen Theorem) (It is a quantitative and non-asymptotic version of CLT) \\(\\forall t\\), we have: \\[ \\Big| P(\\frac{\\sqrt n}{\\sigma} [\\frac{1}{n}\\sum_{i=1}^n (Z_i - m)] \\geq t) - \\int_t^\\infty \\frac{e^{-s^2/2}}{\\sqrt {2\\pi}} ds \\Big| \\leq \\frac{c \\gamma}{\\sigma^3 \\sqrt{n}}, \\] where \\(\\gamma = E(|Z_1|^3) &lt; \\infty\\). Remark. Berry-Essen Theorem doesn’t provide very precise information about \\(P(\\frac{\\sqrt n}{\\sigma} [\\frac{1}{n}\\sum_{i=1}^n (Z_i - m)] \\geq t)\\) when \\(t\\) is very large. 3.4.2 Concentration Inequalities Goal: To quantify precisely what is the behavior of \\(P(\\frac{\\sqrt n}{\\sigma} \\sum_{i=1}^n (Z_i - m) \\geq t)\\) (tail information). What do we want more precisely: If \\(\\frac{\\sqrt n}{\\sigma} [\\frac{1}{n}\\sum_{i=1}^n (Z_i - m)]\\) was truly a standard Gaussian random variable \\(Z\\), in that case what can we say about \\(P(Z \\geq t)\\)? What we could say is that \\(P(Z \\geq t) \\leq e^{-\\frac{t^2}{2}}\\), \\(\\forall t &gt; 0\\). The concentration inequalities we are after should give us some information similar to the one above. To get there, let us start with the basics: For a given real valued random variable \\(W\\), what can we say about \\(P(W \\geq t)\\) for \\(t \\geq 0\\)? Theorem 3.5 (Markov Inequality) Let \\(t &gt; 0\\), then we have \\[ P(W \\geq t) \\leq E(\\frac{W}{t} ~1_{W \\geq t}) \\leq \\frac{E[|W|]}{t} \\] Proof. \\[ \\begin{aligned} P(W \\geq t) &amp;= E[1_{W \\geq t}]\\\\ &amp;\\leq E[\\frac{W}{t} ~1_{W \\geq t}]\\\\ &amp;\\leq E[\\frac{|W|}{t} ~1_{W \\geq t}]\\\\ &amp;\\leq E[\\frac{|W|}{t}]. \\end{aligned} \\] Remark. Let \\(\\phi: R \\to [0,\\infty)\\) be non-decreasing. Then \\(\\forall t&gt;0\\): \\[ \\begin{aligned} P(W \\geq t) \\leq P\\Big(\\phi(W) \\geq \\phi(t)\\Big) \\underset{M.I.}{\\leq} \\frac{E[\\phi(W)]}{\\phi(t)} \\end{aligned} \\] How about we select \\(\\phi\\) to be \\(\\phi(t) := exp(t \\cdot s)\\), where \\(s&gt;0\\). Then \\(\\forall s&gt;0\\): \\[ P(W \\geq t) \\leq \\frac{E[exp(sW)]}{exp(st)} = exp(-st)E[exp(sW)]. \\] As a result, we have: \\[ P(W \\geq t) \\leq \\underset{s&gt;0}{\\operatorname{inf}}\\{exp(-st) E[exp(sW)]\\} \\text{ (Chernoff&#39;s bound)}. \\] It is clear that we need to understand the behavior of \\(E[exp(sW)]\\). The \\(W\\) we want to apply this to, for example, \\(W:=\\frac{1}{n} \\sum_{i=1}^n (Z_i - m)\\), where the \\(Z_i\\)s are independent with mean \\(m\\). Thus, the \\(W\\) for us should be of the form \\(\\sum_{i=1}^n Z_i\\), where \\(Z_i\\)s are independent and \\(E(Z_i) = 0\\). Lemma 3.2 Suppose \\(Z\\) is a r.v. with \\(E(Z) = 0\\) and \\(\\exists \\text{ constant } a,b\\), \\(s.t. ~a\\leq Z \\leq b\\) (Consequently, \\(a&lt;0\\) and \\(b&gt;0\\)). Then \\(\\forall s&gt;0\\), we have \\[ E[exp(sZ)] \\leq exp(\\frac{s^2(b-a)^2}{8}) \\] Remark. This lemma actually is saying that a bounded random variable is a sub-Gaussian random variable. We say that a random variable \\(Z\\) (with \\(E(Z) = 0\\)) is sub-Gaussian with parameter \\(\\sigma^2\\) if \\[ E(e^{sZ}) \\leq exp(\\frac{\\sigma^2 s^2}{2}), ~s &gt; 0 \\] The right hand side is exactly the moment generating function of a \\(N(0, \\sigma^2)\\). In particular, the lemma is saying that \\(Z\\) satisfying \\(a\\leq b\\) and \\(E(Z) = 0\\) is sub-Gaussian with parameter \\(\\frac{(b-a)^2}{4}\\). Proof. Let \\(Z = \\frac{b-Z}{b-a} a + \\frac{Z-a}{b-a} b\\), then we have \\[ \\begin{aligned} E[exp(sZ)] &amp;= E \\Big[ exp[s(\\frac{b-Z}{b-a} a + \\frac{Z-a}{b-a} b)] \\Big] \\\\&amp;\\underset{convexity}{\\leq} E[\\frac{b-Z}{b-a} exp(sa) + \\frac{Z-a}{b-a} exp(sb)] \\\\&amp;\\underset{E(Z) = 0}{=} \\frac{b}{b-a} exp(sa) - \\frac{a}{b-a} exp(sb) \\end{aligned} \\] Let \\(q = -\\frac{a}{b-a}\\), then \\(\\frac{b}{b-a} = 1-q\\). Then, \\[ \\begin{aligned} E[exp(sZ)] &amp;\\leq (1-q) ~exp(-s(b-a)q) + q ~exp(s(b-a)(1-q))\\\\ &amp;= exp[-s(b-a)q + log\\Big((1-q) + q~exp(s(b-a))\\Big)] \\end{aligned} \\] Let \\(\\psi(h):= -qh + log\\Big( (1-q) + q ~exp(h)\\Big)\\), then \\(\\psi(0)=0\\), \\(\\psi&#39;(0) = 0\\), \\(\\psi&#39;&#39;(h) \\leq \\frac{1}{4} ~\\forall h &gt; 0\\). By Taylor’s Theorem, \\(\\psi(h) \\leq \\frac{1}{2} (\\frac{1}{4} h^2) = \\frac{h^2}{8}\\). As a result, \\[ E[exp(sZ)] \\underset{h = s(b-a)}{\\leq} exp(\\frac{s^2(b-a)^2}{8}) \\] Theorem 3.6 (Hoeffding's Inequality) Let \\(Z_1, \\cdots, Z_n\\) be independent random variable (not necessarily identically distributed) such that: \\(E(Z_i) = 0\\), \\(\\forall i=1,\\cdots, n\\); \\(\\forall i\\), \\(\\exists \\text{ constant } a_i, b_i\\), \\(s.t. ~a_i \\leq Z_i \\leq b_i\\). Then \\(\\forall t\\), we have: \\[ P(\\frac{1}{n} \\sum_{i=1}^n Z_i \\geq t) \\leq exp(\\frac{-2t^2n^2}{\\sum_{i=1}^n (b_i - a_i)^2}) \\] Proof. Let \\(W = \\frac{1}{n} \\sum_{i=1}^n Z_i\\), then \\[ P(W \\geq t) \\underset{\\text{Chernoff&#39;s Inequality}}{\\leq} \\underset{s&gt;0}{\\operatorname{inf}} \\{\\frac{E[e^{\\frac{s}{n} \\sum_{i=1}^n Z_i}]}{e^{st}}\\}, \\] where \\[ E[e^{\\frac{s}{n} \\sum_{i=1}^n Z_i}] = E\\Big[\\prod_{i=1}^n e^{\\frac{s}{n} Z_i}\\Big] \\underset{independence}{=} \\prod_{i=1}^n E[e^{\\frac{s}{n} Z_i}] \\] Using Lemma 3.2, we have: \\[ \\prod_{i=1}^n E[e^{\\frac{s}{n} Z_i}] \\leq \\prod_{i=1}^n exp(\\frac{s^2(b_i-a_i)^2}{8n^2}) = exp(\\frac{s^2}{8n^2} \\sum_{i=1}^n (b_i-a_i)^2) \\] Therefore, \\[ P(W \\geq t) \\leq \\underset{s&gt;0}{\\operatorname{inf}} \\{\\frac{exp(\\frac{s^2}{8n^2} \\sum_{i=1}^n (b_i-a_i)^2)}{exp(st)}\\} = \\underset{s&gt;0}{\\operatorname{inf}} \\{exp(\\frac{s^2}{8n^2} \\sum_{i=1}^n (b_i-a_i)^2 - st)\\} \\] For the quadratic, \\(s^* = \\frac{4tn^2}{\\sum_{i=1}^n (b_i-a_i)^2}\\) minimizes it. As a result, \\[ P(W \\geq t) \\leq exp(\\frac{-2t^2n^2}{\\sum_{i=1}^n (b_i - a_i)^2}) \\] Remark. The \\(Z_i\\)s can have different distributions with \\(E(Z_i) = 0\\) and \\(a_i \\leq Z_i \\leq b_i\\). Independence is essential though. What if \\(E(Z_i) \\neq 0\\)? Let \\(\\tilde Z_i := Z_i - E(Z_i)\\) and \\(a_i \\leq \\tilde Z_i \\leq b_i\\). Then \\(\\forall t&gt;0\\), we have: \\[ P(\\frac{1}{n} \\sum_{i=1}^n (Z_i - E(Z_i)) &gt; t) = P(\\frac{1}{n} \\sum_{i=1}^n \\tilde Z_i &gt; t) \\leq exp(\\frac{2n^2 t^2}{\\sum_{i=1}^n (b_i - a_i)^2}) \\] \\(\\forall t &gt; 0\\), we have: \\[ \\begin{aligned} P(\\frac{1}{n} \\sum_{i=1}^n (Z_i - E(Z_i)) &gt; t) &amp;\\leq exp(\\frac{2n^2 t^2}{\\sum_{i=1}^n (b_i - a_i)^2}) \\end{aligned} \\] and \\[ \\begin{aligned} P(\\frac{1}{n} \\sum_{i=1}^n (E(Z_i) - Z_i) \\geq t) &amp;\\leq exp(\\frac{2n^2 t^2}{\\sum_{i=1}^n (b_i - a_i)^2}) \\end{aligned} \\] As a result, \\[ \\begin{aligned} P\\Big(|\\frac{1}{n} \\sum_{i=1}^n (Z_i - E(Z_i))| \\geq t \\Big) &amp;\\leq P(\\frac{1}{n} \\sum_{i=1}^n (Z_i - E(Z_i)) &gt; t) + P(\\frac{1}{n} \\sum_{i=1}^n (E(Z_i) - Z_i) \\geq t) \\\\ &amp;\\leq 2~exp(\\frac{2n^2 t^2}{\\sum_{i=1}^n (b_i - a_i)^2}) \\end{aligned} \\] Suppose all \\(Z_i\\)s come from the same distribution, say Uniform or Gaussian. According to Theorem 3.6, the right hand side (\\(exp(\\frac{2n^2 t^2}{\\sum_{i=1}^n (b_i - a_i)^2})\\)) would be the same in both cases, which means that Hoeffding’s does not use variance information. Theorem 3.7 (Bernstein's Inequality) Let \\(Z_1, \\cdots, Z_n\\) be independent random variables with \\(E(Z_i) = 0\\) and such that \\(-M \\leq Z_i \\leq M\\), and let \\(\\sigma_i^2 = Var(Z_i)\\), \\(\\forall i = 1,\\cdots,n\\). Then \\(\\forall t&gt;0\\), we have: \\[ P(\\frac{1}{n} \\sum_{i=1}^n Z_i \\geq t) \\leq exp(\\frac{-\\frac{1}{2} t^2n^2}{\\frac{1}{3} Mnt + \\sum_{i=1}^n \\sigma_i^2}) \\] and \\[ P\\Big(| \\frac{1}{n} \\sum_{i=1}^n Z_i | \\geq t\\Big) \\leq 2~exp(\\frac{-\\frac{1}{2} t^2n^2}{\\frac{1}{3} Mnt + \\sum_{i=1}^n \\sigma_i^2}) \\] Remark. Suppose \\(\\forall i\\), \\(\\sigma_i^2 &lt; \\sigma^2\\), then we have \\[ P(\\frac{1}{n} \\sum_{i=1}^n Z_i \\geq t) \\leq exp(\\frac{-\\frac{1}{2} t^2n}{\\frac{1}{3} Mt + \\sigma^2}) \\] Hoeffding’s v.s. Bernstein’s: Let \\(a_i = -M\\), \\(b_i = M\\), \\(\\sigma^2 = Var(Z_i)\\). Then for Hoeffding’s, we have: \\[ \\begin{aligned} P(\\frac{1}{n} \\sum_{i=1}^n Z_i \\geq t) &amp;\\leq exp(\\frac{-2t^2n^2}{\\sum_{i=1}^n (b_i - a_i)^2})\\\\ &amp;= exp(\\frac{-2t^2n^2}{4n M^2})\\\\ &amp;= exp(\\frac{-t^2n}{2M^2}) \\end{aligned} \\] For Bernstein’s, we have: \\[ \\begin{aligned} P(\\frac{1}{n} \\sum_{i=1}^n Z_i \\geq t) &amp;\\leq exp(\\frac{-\\frac{1}{2} t^2n^2}{\\frac{1}{3} Mnt + \\sum_{i=1}^n \\sigma^2})\\\\ &amp;= exp(\\frac{-\\frac{1}{2} t^2n}{\\frac{1}{3} Mt + \\sigma^2}) \\end{aligned} \\] As \\[ \\frac{-\\frac{1}{2} t^2n}{\\frac{1}{3} Mt + \\sigma^2} \\leq \\frac{-\\frac{1}{2}t^2n}{M^2} \\Leftrightarrow M^2 \\geq \\sigma^2 + \\frac{1}{3}Mt \\] which means that \\(M^2 \\geq \\sigma^2 + \\frac{1}{3} Mt, ~\\forall t \\in [0,M]\\), or \\(\\frac{2}{3}M^2 \\geq \\sigma^2\\). As a result, when \\(\\sigma^2\\) is considerably smaller than \\(M^2\\), we should use Bernstein’s Inequality rather than Hoeffding’s Inequality. In general, both inequalities have the form of \\[ P(| W_n - E(W_n) | \\geq t) \\leq 2 ~exp(\\cdots) \\] i.e. what is the likelihood that some variable is away from its mean more than distance \\(t\\). Summary: all of these are theorems about sums of independent random variable. 3.4.3 More about Con-Ineq Let \\(Z_1, \\cdots, Z_n\\) be real-valued random variables. Also that \\(U_1, \\cdots, U_n\\) be another sequence of random variables (not necessarily real-valued). We say \\(\\{Z_i\\}_{i=1,\\cdots,n}\\) is a martingale difference sequence w.r.t. \\(\\{U_i\\}_{i=1,\\cdots,n}\\) if \\(Z_k = h_k(U_1, \\cdots, U_k)\\), \\(\\forall k=1,\\cdots,n\\) \\(E(Z_{k+1} | U_1, \\cdots, U_k) = 0\\), \\(\\forall k = 1,\\cdots, n-1\\). Remark. Suppose that \\(Z_1, \\cdots, Z_n\\) are independent random variables with mean 0 and \\(U_i = Z_i\\), \\(\\forall i=1,\\cdots,n\\). Then \\(\\{Z_i\\}_{i=1,\\cdots,n}\\) is a MDS w.r.t. (relative to) \\(\\{U_i\\}_{i=1,\\cdots,n}\\) Theorem 3.8 (Hoeffding's Inequality for MDS) Let \\(\\{Z_i\\}_{i=1,\\cdots,n}\\) be a MDS relative to \\(\\{X_i\\}_{i=1,\\cdots,n}\\) (which generalizes “Let \\(\\{Z_i\\}_{i=1,\\cdots,n}\\) be independent r.v.s with mean 0”). Assume that \\(\\forall i=1,\\cdots, n\\), we have: \\[ V_i \\leq Z_i \\leq V_i + C_i, \\] where \\(C_i &gt;0\\) is a fixed number, and \\(V_i\\) can be a r.v. and \\(V_i = \\psi_i(X_1, \\cdots, X_{i-1})\\), \\(\\forall i\\) (which generalizes the assumption \\(a_i \\leq Z_i \\leq b_i\\)). Then, \\(\\forall t&gt;0\\), we have: \\[ P(\\frac{1}{n}\\sum_{i=1}^n Z_i \\geq t) \\leq exp(\\frac{-2t^2n^2}{\\sum_{i=1}^n C_i^2}) \\] Theorem 3.9 (McDiarmid's Inequality) Let \\(X_1, \\cdots, X_n\\) be independent r.v.s in \\(R^d\\). Suppose we have a function \\(g: (R^d)^n \\to R\\), i.e. \\(g(x_1, \\cdots, x_n) \\in R, ~x_1, \\cdots, x_n \\in R^d\\), satisfying: \\(\\forall i=1,\\cdots, n\\), \\[ \\underset{x_1, \\cdots, x_n, x_i&#39;}{\\operatorname{sup}} \\Big| g(x_1, \\cdots, x_n) - g(x_1, \\cdots, x_{i-1}, x_i&#39;, x_{i+1}, \\cdots, x_n) \\Big| \\leq C_i. \\] Then we have: \\[ P(W_n - E(W_n) \\geq t) \\leq exp(\\frac{-2t^2}{\\sum_{i=1}^n C_i^2}), \\] where \\(W_n := g(X_1, \\cdots, X_n)\\). Proof. Idea: To show that \\(W_n - E(W_n) = \\sum_{i=1}^n Z_i\\) for a suitable MDS satisfying the assumptions in Theorem 3.8. Let \\(Z_k:= E(W_n | X_1, \\cdots, X_k) - E(W_n | X_1, \\cdots, X_{k-1})\\), \\(k \\geq 2\\); \\(Z_1 := E(W_n | X_1) - E(W_n)\\). Then we have: we can write \\(W_n - E(W_n) = \\sum_{i=1}^n Z_i\\): \\[ \\begin{aligned} \\sum_{i=1}^n Z_i &amp;= E(W_n | X_1, \\cdots, X_n) - E(W_n)\\\\ &amp;= E(g(X_1, \\cdots, X_n) | X_1, \\cdots, X_n) - E(W_n)\\\\ &amp;= g(X_1, \\cdots, X_n)- E(W_n)\\\\ &amp;= W_n- E(W_n) \\end{aligned} \\] \\(\\{Z_i\\}\\) is a MDS relative to \\(\\{X_i\\}\\): \\[ \\begin{aligned} Z_k &amp;= E(W_n | X_1, \\cdots, X_k) - E(W_n | X_1, \\cdots, X_{k-1})\\\\ &amp;= \\tilde h_k(X_1, \\cdots, X_k) - \\tilde h_{k-1}(X_1, \\cdots, X_{k-1})\\\\ &amp;= h_k(X_1, \\cdots, X_k) \\end{aligned} \\] and \\[ \\begin{aligned} E(Z_{k+1} | X_1, \\cdots, X_k) &amp;= E\\Big(E(W_n |X_1, \\cdots, X_{k+1}) - E(W_n | X_1, \\cdots, X_k) \\Big| X_1, \\cdots, X_k \\Big)\\\\ &amp;= E\\Big( E(W_n |X_1, \\cdots, X_{k+1}) \\Big | X_1, \\cdots, X_k\\Big) - E\\Big( E(W_n |X_1, \\cdots, X_k) \\Big | X_1, \\cdots, X_k\\Big)\\\\ &amp;\\underset{\\text{Tower Property}}{=} E(W_n |X_1, \\cdots, X_k) - E(W_n |X_1, \\cdots, X_k)\\\\ &amp;= 0 \\end{aligned} \\] we can bound \\(V_k \\leq Z_k \\leq V_k + C_k\\) for some \\(V_k, C_k\\): (Show that in HW2) 3.4.4 Strong Consistency Statements that may encounter (\\(P(|W_n - E(W_n)| \\geq t) \\leq 2 exp(-cnt^2)\\)): With probability greater than \\(1-\\delta\\), we have: \\(|W_n - E(W_n)| \\leq f(\\delta, n)\\) (fixing threshold) With probability greater than \\(1-\\delta\\), we have: \\(|W_n - E(W_n)| \\leq \\sqrt{\\frac{1}{cn} log(\\frac{2}{\\delta})}\\) (let \\(\\delta = 2 exp(-cnt^2)\\), i.e. fixing probability) Theorem 3.10 (Borel-Cantelli Theorem) Let \\(E_1, E_2, \\cdots\\) be events in a probability space \\((\\Omega, \\mathcal F, P)\\), \\(\\sum_{i=1}^\\infty P(E_i) \\leq \\infty\\) (the events \\(E_i\\) become less and less likely), then for \\(E=\\{\\omega \\in \\Omega: ~\\exists N(\\omega), s.t. ~ \\forall n \\geq N(\\omega), \\omega \\in E_n^c\\}\\), we have \\(P(E) = 1\\). Example 3.9 \\(Z_1, Z_2, \\cdots\\) independent and \\(Z_i \\sim Bernoulli(p_i)\\), \\(\\sum_{i=1}^\\infty p_i &lt; \\infty\\). Notice \\(p_i = P(Z_i=1) \\to 0\\) as \\(i \\to \\infty\\). Example 3.10 \\(Z_1, Z_2, \\cdots\\) are i.i.d. r.v.s with mean \\(m\\) and \\(|Z_i| \\leq M\\), \\(\\forall i=1,2,\\cdots\\) By Hoeffding’s Inequality, \\(\\forall t&gt;0\\), we have: \\[ P(|\\frac{1}{n}\\sum_{i=1}^n Z_i - m| \\geq t) \\leq 2 ~exp(\\frac{-nt^2}{2M^2}) \\] The idea is to define a sequence \\(\\{t_n\\}_{n\\in N}\\) such that \\(t_n \\to 0\\) and \\(\\sum_{n=1}^\\infty 2 ~exp(\\frac{-nt_n^2}{2M^2}) &lt; \\infty\\). Then let \\(E_n := \\{|\\frac{1}{n}\\sum_{i=1}^n Z_i - m| \\geq t_n \\}\\). As a result, \\(\\sum_{n=1}^\\infty P(E_n) \\leq 2~exp(\\frac{-nt^2}{2M^2}) &lt; \\infty\\). By Borel-Cantelli: \\(P(E) = 1\\), where \\(E = \\{\\omega \\in \\Omega: \\forall n \\text{ large enough, } \\omega \\in E_n^c \\}\\). Therefore, what we are saying is that for almost every \\(\\omega \\in \\Omega\\), \\(\\forall\\) large enough \\(n\\), we have \\(|\\frac{1}{n}\\sum_{i=1}^n Z_i - m| \\leq t_n\\). As \\(t_n \\to 0\\), we then have for almost every \\(\\omega \\in \\Omega\\), \\(\\underset{n \\to \\infty}{\\operatorname{lim}} |\\frac{1}{n}\\sum_{i=1}^n Z_i - m| = 0\\). For example, \\(t_n := \\sqrt{4M^2 \\frac{log(n)}{n}}\\) satisfies the above assumptions. Theorem 3.11 Let \\(\\hat{\\mathfrak f}_n\\) be a histogram classifier built from data \\((x_1, y_1), \\cdots, (x_n, y_n)\\). Let \\(h_n\\) be the length-scale associated to \\(\\hat{\\mathfrak f}_n\\). If \\(\\begin{cases} h_n \\to 0 ~as~ n\\to \\infty\\\\ nh_n^d \\to \\infty ~as~ n \\to \\infty\\end{cases}\\), then \\(\\{\\hat{\\mathfrak f}_n\\}\\) is universally strong consistent. Proof. Recall histogram classifiers 3.5 \\(\\forall z\\in R^d\\), denote \\(A_n(z)\\) by the cell in the grid that contains \\(z\\). Then, \\(\\omega_{in}(X) = \\frac{1_{A_n(X)}(x_i)}{N_n(X)}\\), where \\(1_{A_n(X)}(x_i) := \\begin{cases}1&amp;x_i \\in A_n(X)\\\\0&amp;o.w. \\end{cases}\\), \\(N_n(X):= \\#\\{j ~s.t. 1_{A_n(X)}(x_j)=1 \\}\\). As \\(\\hat \\eta_n(X) = \\sum_{i=1}^n Y_i \\omega_{in}(X) = \\sum_{i=1}^n Y_i \\frac{1_{A_n(X)}(x_i)}{N_n(X)}\\), we have \\[ \\hat \\eta_n(X) \\geq \\frac{1}{2} \\Leftrightarrow \\sum_{i=1}^n Y_i1_{A_n(X)}(x_i) \\geq \\sum_{i=1}^n (1-Y_i)1_{A_n(X)}(x_i) \\] Let \\(\\rho_X(A_n(x)):= P_{(X,Y) \\sim \\rho} (X\\in A_n(x))\\), \\(\\hat \\alpha_n^0(x):= \\frac{\\sum_{i=1}^n (1-Y_i) 1_{A_n(X)}(x_i)}{n\\rho_X(A_n(x))}\\), \\(\\hat \\alpha_n^1(x):=\\frac{\\sum_{i=1}^n Y_i 1_{A_n(X)}(x_i)}{n\\rho_X(A_n(x))}\\), then \\[ \\hat \\eta_n(x) \\geq \\frac{1}{2} \\Leftrightarrow \\hat \\alpha_n^0(x) \\geq \\hat \\alpha_n^1(x) \\] It can be shown that \\(R(\\hat{\\mathfrak f}_n) - R^* \\leq E_{(X,Y)\\sim \\rho} \\Big[|1-\\eta(X) - \\hat \\alpha_n^0(X)|\\Big] + E_{(X,Y)\\sim \\rho} \\Big[|\\eta(X) - \\hat \\alpha_n^1(X)|\\Big]\\) (use \\(\\hat \\alpha_n^0(X)\\) to estimate \\(1-\\eta(X)\\) and use \\(\\hat \\alpha_n^1(X)\\) to estimate \\(\\eta(X)\\)). Let \\[ \\begin{aligned} g_n((x_1, y_1), \\cdots, (x_n, y_n)) &amp;= E_{(X,Y)\\sim \\rho} \\Big[|\\eta(X) - \\hat \\alpha_n^1(X)|\\Big]\\\\ &amp;= g_n((x_1, y_1), \\cdots, (x_n, y_n)) - E_{(x_1, y_1), \\cdots, (x_n, y_n)[g_n((x_1, y_1), \\cdots, (x_n, y_n))]} \\text{ (variance)}\\\\ &amp;+E_{(x_1, y_1), \\cdots, (x_n, y_n)[g_n((x_1, y_1), \\cdots, (x_n, y_n))]} \\text{ (bias)} \\end{aligned} \\] then for the bias term, it goes to 0 as \\(n \\to \\infty\\) following a slight generalization of Stone’s Theorem since here weights don’t exactly add to 1. For the variance term, we have: \\[ \\begin{aligned} g_n((x_1, y_1), \\cdots, (x_i,y_i),\\cdots, (x_n, y_n)) &amp;= E_{(X,Y) \\sim \\rho}\\Big[ |\\eta(X) - \\frac{\\sum_{k=1}^n y_k 1_{A_n(X)}(x_k)}{n\\rho_X(A_n(x))}| \\Big]\\\\ &amp;= E_{(X,Y) \\sim \\rho}\\Big[ |\\eta(X) - \\frac{\\sum_{k\\neq i} y_k 1_{A_n(X)}(x_k)}{n\\rho_X(A_n(x))} + \\frac{y_i 1_{A_n(X)}(x_i)}{n\\rho_X(A_n(x))}| \\Big] \\end{aligned} \\] and \\[ \\begin{aligned} g_n((x_1, y_1), \\cdots, (x_i&#39;,y_i&#39;),\\cdots, (x_n, y_n)) &amp;= E_{(X,Y) \\sim \\rho}\\Big[ |\\eta(X) - \\frac{\\sum_{k\\neq i} y_k 1_{A_n(X)}(x_k)}{n\\rho_X(A_n(x))} + \\frac{y_i&#39; 1_{A_n(X)}(x_i&#39;)}{n\\rho_X(A_n(x))}| \\Big] \\end{aligned} \\] As a reuslt, \\[ \\begin{aligned} | g_n((x_1, y_1), \\cdots, (x_i,y_i),\\cdots, (x_n, y_n)) -\\\\ g_n((x_1, y_1), \\cdots, (x_i&#39;,y_i&#39;),\\cdots, (x_n, y_n))| &amp;\\leq E_{(X,Y)\\sim \\rho}[\\frac{y_i 1_{A_n(X)}(x_i)}{n\\rho_X(A_n(x))} + \\frac{y_i&#39; 1_{A_n(X)}(x_i&#39;)}{n\\rho_X(A_n(x))}]\\\\ &amp;\\underset{x_i \\in A_n(X) \\Leftrightarrow X \\in A_n(x_i)}{\\leq} E[\\frac{1_{A_n(x_i)}(X)}{n\\rho_X(A_n(x_i))}] + E[\\frac{1_{A_n(x_i&#39;)}(X)}{n\\rho_X(A_n(x_i&#39;))}]\\\\ &amp;= \\frac{1}{n \\rho_X(A_n(x_i))}P(X\\in A_n(x_i)) + \\frac{1}{n \\rho_X(A_n(x_i&#39;))}P(X\\in A_n(x_i&#39;))\\\\ &amp;= \\frac{2}{n} \\end{aligned} \\] Let \\(C_i = \\frac{2}{n}\\), by McDiarmid’s Inequality, we have: \\[ \\begin{aligned} P(|g_n - E[g_n]| \\geq t) &amp;\\leq 2~exp(\\frac{-2t^2}{n\\sum C_i^2})\\\\ &amp;= 2~exp(-\\frac{1}{2}nt^2) \\end{aligned} \\] Let \\(t_n:= \\sqrt{c \\frac{log(n)}{n}}\\), where we can choose \\(C\\) large enough so that by Borel-Cantelli Theorem, we have: with probability 1, \\(\\forall\\) large enough \\(n\\), we have \\(|g_n - E[g_n]| \\leq t_n\\). As a result, we have \\(|g_n - E[g_n]| \\to 0\\) as \\(n \\to \\infty\\) a.s. "],["empirical-risk-minimization.html", "Chapter 4 Empirical Risk Minimization 4.1 Questions 4.2 Concentration Bounds for \\(\\underset{\\mathfrak f \\in \\mathcal F}{\\operatorname{sup}} | R_n(\\mathfrak f) - R(\\mathfrak f) |\\)", " Chapter 4 Empirical Risk Minimization Definition 4.1 (Empirical Risk) Given \\((x_1, y_1), \\cdots, (x_n, y_n)\\), \\(\\mathfrak f: \\mathcal X \\to \\{0,1\\}\\), define the empirical risk: \\(R_n(\\mathcal f) = \\frac{1}{n}\\sum_{i=1}^n 1_{\\mathfrak f(x_i) \\neq y_i}\\). Goal: To understand how does \\(R(\\mathfrak f_n^*)\\) behave as a function of \\(n\\) and the training data, where \\(\\mathfrak f_n^* \\in \\underset{\\mathfrak f \\in \\mathcal F}{\\operatorname{argmin}} R_n(\\mathfrak f)\\). 4.1 Questions Suppose for a moment that we have proved that with probability greater than \\(1-\\delta\\): \\(\\underset{\\mathfrak f \\in \\mathcal F}{\\operatorname{sup}} | R_n(\\mathfrak f) - R(\\mathfrak f) | \\leq \\epsilon(n, \\mathcal F, \\delta)\\), we have: \\(\\mathfrak f_n^* \\in \\mathcal F\\) \\(\\mathfrak f^* \\in \\mathcal F\\) \\(R_n(\\mathfrak f_n^*) \\leq R_n(\\mathfrak f^*)\\) \\(R(\\mathfrak f^*) \\leq R(\\mathfrak f_n^*)\\) Comparison between empirical risk and true risk: With probability greater than \\(1-\\delta\\), \\(R(\\mathfrak f_n^*) \\leq R_n(\\mathfrak f_n^*) + \\epsilon(n, \\mathcal F, \\delta)\\). \\[ \\begin{aligned} | R(\\mathfrak f_n^*) - R_n(\\mathfrak f_n^*) | &amp;\\leq \\underset{\\mathfrak f \\in \\mathcal F}{\\operatorname{sup}} | R_n(\\mathfrak f) - R(\\mathfrak f) |\\\\ &amp;\\leq \\epsilon(n, \\mathcal F, \\delta) \\end{aligned} \\] Let \\(\\mathfrak f^* \\in \\underset{\\mathfrak f \\in \\mathcal F}{\\operatorname{argmin}} R(\\mathfrak f)\\), with probability greater than \\(1-\\delta\\): \\(R(\\mathfrak f_n^*) \\leq R(\\mathfrak f^*) + \\epsilon(n, \\mathcal F, \\delta)\\). \\[ \\begin{aligned} 0 \\leq R(\\mathfrak f_n^*) - R(\\mathfrak f^*) &amp;= R(\\mathfrak f_n^*) - R_n(\\mathfrak f_n^*) \\\\ &amp;\\quad + R_n(\\mathfrak f_n^*) - R_n(\\mathfrak f^*) \\\\ &amp;\\quad+ R_n(\\mathfrak f^*) - R(\\mathfrak f^*) \\quad(\\leq 0)\\\\ &amp;\\leq R(\\mathfrak f_n^*) - R_n(\\mathfrak f_n^*)\\\\ &amp;\\quad+ R(\\mathfrak f_n^*) - R_n(\\mathfrak f_n^*)\\\\ &amp;\\leq 2| R(\\mathfrak f_n^*) - R_n(\\mathfrak f_n^*) |\\\\ &amp;\\leq 2 \\epsilon(n, \\mathcal F, \\delta) \\end{aligned} \\] Comparison between true risk of \\(\\mathfrak f_n^*\\) and Bayes risk: With probability greater than \\(1-\\delta\\): \\(R(\\mathfrak f_n^*) \\leq R(\\mathfrak f_B) + \\epsilon(n, \\mathcal F, \\delta)\\). \\[ \\begin{aligned} R(\\mathfrak f_n^*) &amp;\\leq R(\\mathfrak f^*) + \\epsilon(n, \\mathcal F, \\delta)\\\\ &amp;= R(\\mathfrak f_B) \\\\ &amp;\\quad+ R(\\mathfrak f^*) - R(\\mathfrak f_B) \\quad (\\leq 0)\\\\ &amp;\\quad+ \\epsilon(n, \\mathcal F, \\delta)\\\\ &amp;\\leq R(\\mathfrak f_B) + \\epsilon(n, \\mathcal F, \\delta) \\end{aligned} \\] 4.2 Concentration Bounds for \\(\\underset{\\mathfrak f \\in \\mathcal F}{\\operatorname{sup}} | R_n(\\mathfrak f) - R(\\mathfrak f) |\\) 4.2.1 In terms of Shattering Number Theorem 4.1 (Vapnick-Chervonenkis) \\(\\underset{\\mathfrak f \\in \\mathcal F}{\\operatorname{sup}} | R_n(\\mathfrak f) - R(\\mathfrak f) | \\to 0\\) in probability iff \\(| R(\\mathfrak f_n^*) - R(\\mathfrak f^*) | \\to 0\\) in probability. Suppose \\(| \\mathcal F | &lt; \\infty\\), where we can use a union bound: \\[ \\begin{aligned} P(\\underset{\\mathfrak f \\in \\mathcal F}{\\operatorname{sup}} | R_n(\\mathfrak f) - R(\\mathfrak f) | \\geq t) &amp;= P(\\exists \\mathfrak f \\in \\mathcal F \\quad s.t. \\quad | R_n(\\mathfrak f) - R(\\mathfrak f) | \\geq t)\\\\ &amp;= P(\\bigcup_{\\mathfrak f \\in \\mathcal F} \\{| R_n(\\mathfrak f) - R(\\mathfrak f) | \\geq t\\})\\\\ &amp;\\leq \\sum_{\\mathfrak f \\in \\mathcal F} P(| R_n(\\mathfrak f) - R(\\mathfrak f) | \\geq t)\\\\ &amp;\\underset{Hoeffdings}{\\leq} | \\mathcal F| \\cdot 2\\operatorname{exp}(-\\frac{nt^2}{8}) \\end{aligned} \\] To extend to a setting where \\(| \\mathcal F | = \\infty\\), we have: Definition 4.2 (Shattering Number) \\(S(n, \\mathcal F) = \\underset{x_1, \\cdots, x_n}{\\operatorname{sup}} | \\mathcal F_{x_1, \\cdots, x_n}|\\) Definition 4.3 (VC Dimension) \\(\\forall n &lt; VC(\\mathcal F)\\), \\(S(n, \\mathcal F) = 2^n\\), and \\(S(VC(\\mathcal F), \\mathcal F) &lt; 2^{VC(\\mathcal F)}\\). Symmetrization: Theorem 4.2 Let \\(t&gt;0\\) be such that \\(t \\geq \\sqrt{\\frac{2}{n}}\\). Let \\(R_n\\) be the empirical risk associated to \\((x_1, y_1), \\cdots, (x_n, y_n) \\underset{i.i.d}{\\sim} \\rho\\). Let \\(R_n&#39;\\) be the empirical risk associated to \\((x_1&#39;, y_1&#39;), \\cdots, (x_n&#39;, y_n&#39;) \\underset{i.i.d}{\\sim} \\rho\\) independent from \\((x_1, y_1), \\cdots, (x_n, y_n)\\): \\[ \\begin{aligned} &amp;R_n(\\mathfrak f) = \\frac{1}{n} \\sum_{i=1}^n 1_{\\mathfrak f(x_i) \\neq y_i}\\\\ &amp;R_n&#39;(\\mathfrak f) = \\frac{1}{n} \\sum_{i=1}^n 1_{\\mathfrak f(x&#39;_i) \\neq y&#39;_i}\\\\ \\end{aligned} \\] Then we have: \\[ \\begin{aligned} P(\\underset{\\mathfrak f \\in \\mathcal F}{\\operatorname{sup}} | R_n(\\mathfrak f) - R(\\mathfrak f) | \\geq t) \\leq 2P(\\underset{\\mathfrak f \\in \\mathcal F}{\\operatorname{sup}} | R_n(\\mathfrak f) - R&#39;_n(\\mathfrak f) | \\geq \\frac{t}{2}) \\end{aligned} \\] Proof. Suppose \\(\\tilde{\\mathfrak f}_n \\in \\mathcal F\\) is a maximizer for \\(\\underset{\\mathfrak f \\in \\mathcal F}{\\operatorname{sup}} | R_n(\\mathfrak f) - R(\\mathfrak f) |\\). Claim: \\[ \\begin{aligned} 1_{| R(\\tilde{\\mathfrak f}_n) - R_n(\\tilde{\\mathfrak f}_n) | &gt; t} \\cdot 1_{| R(\\tilde{\\mathfrak f}_n) - R&#39;_n(\\tilde{\\mathfrak f}_n) | &lt; \\frac{t}{2}} \\leq 1_{| R&#39;_n(\\tilde{\\mathfrak f}_n) - R_n(\\tilde{\\mathfrak f}_n) | &gt; \\frac{t}{2}} \\end{aligned} \\] Case 1: LHS = 0, then there is nothing to prove. Case 2: LHS = 1, then we have \\(| R(\\tilde{\\mathfrak f}_n) - R_n(\\tilde{\\mathfrak f}_n) | &gt; t\\) and \\(| R(\\tilde{\\mathfrak f}_n) - R&#39;_n(\\tilde{\\mathfrak f}_n) | &lt; \\frac{t}{2}\\). Thus, \\[ \\begin{aligned} | R&#39;_n(\\tilde{\\mathfrak f}_n) - R_n(\\tilde{\\mathfrak f}_n) | &amp;\\geq | R(\\tilde{\\mathfrak f}_n) - R_n(\\tilde{\\mathfrak f}_n) | - | R(\\tilde{\\mathfrak f}_n) - R&#39;_n(\\tilde{\\mathfrak f}_n) |\\\\ &amp;&gt; t - \\frac{t}{2} = \\frac{t}{2} \\end{aligned} \\] which means RHS = 1. Then, for \\(R&#39;_n(\\tilde{\\mathfrak f}_n) = \\frac{1}{n} \\sum_{i=1}^n 1_{\\tilde{\\mathfrak f}_n(x&#39;_i) \\neq y_i}\\), we have \\(E[R&#39;_n(\\tilde{\\mathfrak f}_n) | (x_1, y_1), \\cdots, (x_n, y_n)] = R(\\tilde{\\mathfrak f}_n)\\). Thus, \\[ \\begin{aligned} Var(R&#39;_n(\\tilde{\\mathfrak f}_n) - R(\\tilde{\\mathfrak f}_n) | (x_1, y_1), \\cdots, (x_n, y_n)) &amp;= \\frac{1}{n^2} \\sum_{i=1}^n Var(\\frac{1}{n} \\sum_{i=1}^n 1_{\\tilde{\\mathfrak f}_n(x&#39;_i) \\neq y_i} | (x_1, y_1), \\cdots, (x_n, y_n))\\\\ &amp;\\leq \\frac{1}{n^2} \\cdot n \\cdot \\frac{1}{4}\\\\ &amp;= \\frac{1}{4n} \\end{aligned} \\] Then, \\[ \\begin{aligned} 1_{| R(\\tilde{\\mathfrak f}_n) - R_n(\\tilde{\\mathfrak f}_n) | &gt; t} \\cdot E[1_{| R(\\tilde{\\mathfrak f}_n) - R&#39;_n(\\tilde{\\mathfrak f}_n) | &lt; \\frac{t}{2}} | (x_1, y_1), \\cdots, (x_n, y_n)] \\leq E[1_{| R&#39;_n(\\tilde{\\mathfrak f}_n) - R_n(\\tilde{\\mathfrak f}_n) | &gt; \\frac{t}{2}} | (x_1, y_1), \\cdots, (x_n, y_n)] \\end{aligned} \\] As \\[ \\begin{aligned} E[1_{| R(\\tilde{\\mathfrak f}_n) - R&#39;_n(\\tilde{\\mathfrak f}_n) | &lt; \\frac{t}{2}} | (x_1, y_1), \\cdots, (x_n, y_n)] &amp;= 1 - E[1_{| R(\\tilde{\\mathfrak f}_n) - R&#39;_n(\\tilde{\\mathfrak f}_n) | \\geq \\frac{t}{2}} | (x_1, y_1), \\cdots, (x_n, y_n)]\\\\ &amp;\\geq 1 - (\\frac{2}{t})^2 Var(R&#39;_n(\\tilde{\\mathfrak f}_n) - R(\\tilde{\\mathfrak f}_n) | (x_1, y_1), \\cdots, (x_n, y_n))\\\\ &amp;\\geq 1 - \\frac{1}{t^2n}\\\\ &amp;\\underset{t \\geq \\sqrt{\\frac{2}{n}}}{\\geq} \\frac{1}{2} \\end{aligned} \\] we have: \\[ \\begin{aligned} 1_{| R(\\tilde{\\mathfrak f}_n) - R_n(\\tilde{\\mathfrak f}_n) | &gt; t} \\leq 2 E[1_{| R&#39;_n(\\tilde{\\mathfrak f}_n) - R_n(\\tilde{\\mathfrak f}_n) | &gt; \\frac{t}{2}} | (x_1, y_1), \\cdots, (x_n, y_n)] \\end{aligned} \\] Take expectation of both sides, we then have: \\[ \\begin{aligned} P(\\underset{\\mathfrak f \\in \\mathcal F}{\\operatorname{sup}} | R_n(\\mathfrak f) - R(\\mathfrak f) | \\geq t) &amp;\\leq 2P(| R&#39;_n(\\tilde{\\mathfrak f}_n) - R_n(\\tilde{\\mathfrak f}_n) | \\geq \\frac{t}{2})\\\\ &amp;\\leq 2 P(\\underset{\\mathfrak f \\in \\mathcal F}{\\operatorname{sup}} | R&#39;_n(\\mathfrak f) - R_n(\\mathfrak f) | \\geq \\frac{t}{2}) \\end{aligned} \\] How do we bound \\(P(\\underset{\\mathfrak f \\in \\mathcal F}{\\operatorname{sup}} | R&#39;_n(\\mathfrak f) - R_n(\\mathfrak f) | \\geq \\frac{t}{2})\\)? At most the number of different values that \\(R&#39;_n(\\mathfrak f) - R_n(\\mathfrak f)\\) can take when we change \\(\\mathfrak f \\in \\mathcal F\\) is the number of assignment that the family \\(\\mathcal F\\) induces on \\((x_1, \\cdots, x_n, x&#39;_1, \\cdots, x&#39;_n)\\). Therefore, \\[ \\begin{aligned} P(\\underset{\\mathfrak f \\in \\mathcal F}{\\operatorname{sup}} | R&#39;_n(\\mathfrak f) - R_n(\\mathfrak f) | \\geq \\frac{t}{2}) &amp;= P(\\underset{\\mathfrak f \\in \\mathcal F_{x_1, \\cdots, x_n, x&#39;_1, \\cdots, x&#39;_n}}{\\operatorname{max}} | R&#39;_n(\\mathfrak f) - R_n(\\mathfrak f) | \\geq \\frac{t}{2})\\\\ &amp;\\underset{S(2n, \\mathcal F) = \\operatorname{sup} |\\mathcal F_{x_1, \\cdots, x_n, x&#39;_1, \\cdots, x&#39;_n}|}{\\leq} S(2n, \\mathcal F) \\cdot 2\\operatorname{exp}(-\\frac{nt^2}{8}) \\end{aligned} \\] Thus, combining the Symmetrization argument and the above we have: Theorem 4.3 (Vapnick-Chervonenkisi Therorem) Let \\(t&gt;0\\) be such that \\(t \\geq \\sqrt{\\frac{2}{n}}\\). Then, \\[ \\begin{aligned} P(\\underset{\\mathfrak f \\in \\mathcal F}{\\operatorname{sup}} | R_n(\\mathfrak f) - R(\\mathfrak f) | \\geq t) \\leq 4 S(2n, \\mathcal F) \\cdot 2\\operatorname{exp}(-\\frac{nt^2}{8}) \\end{aligned} \\] Let \\(\\delta = 4 S(2n, \\mathcal F) \\cdot 2\\operatorname{exp}(-\\frac{nt^2}{8})\\), we have \\(t = \\sqrt{\\frac{8 \\operatorname{log} (\\frac{4S(2n, \\mathcal F)}{\\delta})}{n}}\\). Then, with probability of at least \\(1-\\delta\\), we have: \\[ \\begin{aligned} \\underset{\\mathfrak f \\in \\mathcal F}{\\operatorname{sup}} | R_n(\\mathfrak f) - R(\\mathfrak f) | &amp;\\leq t\\\\ &amp;= \\sqrt{\\frac{8 \\operatorname{log} (\\frac{4S(2n, \\mathcal F)}{\\delta})}{n}}\\\\ &amp;= \\sqrt{\\frac{8 \\operatorname{log} (4S(2n, \\mathcal F)) + 8\\operatorname{log (\\frac{1}{\\delta})}}{n}} \\end{aligned} \\] We call \\(0 \\leq R(f_n^* - R^*) \\to 0\\) as \\(n \\to \\infty\\) a restricted (\\(\\mathfrak f \\in \\mathcal F\\)) consistency statement. 4.2.2 In terms of VC Dimension Theorem 4.4 (Vapnick,Chervonenkisi,Sauer,Shelah) If \\(VC(\\mathcal F) &lt; \\infty\\), then: \\[ S(n,\\mathcal F) \\leq (\\frac{e n}{VC(\\mathcal F)})^{VC(\\mathcal F)} \\] The RHS is a polynomial in n. Corollary 4.1 With probability of at least \\(1-\\delta\\), we have: \\[ \\begin{aligned} \\underset{\\mathfrak f \\in \\mathcal F}{\\operatorname{sup}} | R_n(\\mathfrak f) - R(\\mathfrak f) | &amp;\\leq \\sqrt{\\frac{8 \\operatorname{log} (\\frac{4S(2n, \\mathcal F)}{\\delta})}{n}}\\\\ &amp;\\leq \\sqrt{\\frac{8 \\operatorname{log} (4(\\frac{e n}{VC(\\mathcal F)})^{VC(\\mathcal F)}) + 8\\operatorname{log (\\frac{1}{\\delta})}}{n}}\\\\ &amp;\\approx \\sqrt{\\frac{c \\cdot VC(\\mathcal F) \\operatorname{log} (n) + c\\operatorname{log (\\frac{1}{\\delta})}}{n}} \\end{aligned} \\] If \\(VC(\\mathcal F) = \\infty\\), \\(\\sqrt{\\frac{c \\operatorname{log} (2^n) + c\\operatorname{log (\\frac{1}{\\delta})}}{n}} = \\sqrt{c \\operatorname{log} (2) + \\frac{c\\operatorname{log} (\\frac{1}{\\delta})}{n}}\\), which doesn’t go to 0 as \\(n \\to \\infty\\). Thus, keep VC dimension finite is critical for restricted universal strong consistency of ERM. 4.2.3 In terms of Rademacher Complexity A new convention: let us assume our classifier: \\(\\mathfrak f: \\mathcal X \\to \\{-1,1\\}\\), \\(y_i \\in \\{-1,1\\}\\). Definition 4.4 Given a family of classifier \\(\\mathcal F\\) (\\(\\mathfrak f: \\mathcal X \\to \\{-1,1\\}\\)), we define \\(Rad_n(\\mathcal F) = E[\\underset{\\mathfrak f \\in \\mathcal F}{\\operatorname{sup}} R_n^{\\sigma}(\\mathfrak f)]\\) as Rademacher average. \\(\\tilde{Rad}_n(\\mathcal F) = E_{\\sigma}[\\underset{\\mathfrak f \\in \\mathcal F}{\\operatorname{sup}} R_n^{\\sigma}(\\mathfrak f)]\\) as conditional Rademacher average Here, \\(R_n^{\\sigma}(\\mathfrak f) = \\frac{1}{n} \\sum_{i=1}^n \\sigma_i \\mathfrak f(x_i)\\), where \\(x_1, \\cdots, x_n\\) are \\(i.i.d\\) samples and \\(\\sigma_1, \\cdots, \\sigma_n\\) are \\(i.i.d\\) Rademacher variables (\\(\\sigma_i \\in \\{-1,1\\}\\) and \\(P(\\sigma_i=-1)=P(\\sigma_i=1)=\\frac{1}{2}\\)) that are independent from the data. \\(E\\): expectation over \\(x_1, \\cdots, x_n\\) and over \\(\\sigma_1, \\cdots, \\sigma_n\\). \\(E_\\sigma\\): expectation over \\(\\sigma_1, \\cdots, \\sigma_n\\). In particular, \\(\\tilde{Rad}_n(\\mathcal F)\\) is a random variable that depends on \\(x_1, \\cdots, x_n\\). Theorem 4.5 For all \\(\\delta \\in (0,1)\\), with probability at least \\(1-\\delta\\), we have: \\[ \\underset{\\mathfrak f \\in \\mathcal F}{\\operatorname{sup}} |R(\\mathfrak f) - R_n(\\mathfrak f)| \\leq 2Rad_n(\\mathcal F) + \\sqrt{\\frac{c \\operatorname{log}(\\frac{1}{\\delta})}{n}} \\] Corollary 4.2 If \\(Rad_n(\\mathcal F) \\to 0\\) as \\(n \\to \\infty\\), then ERM with \\(\\mathcal F\\) is (restricted) universally strongly consistent. Unfortunately, \\(Rad_n(\\mathcal F)\\) is still distribution dependent: \\(x_1, \\cdots, x_n \\sim \\rho_X\\), \\(\\sigma_1, \\cdots, \\sigma_n \\sim Rademacher\\). Theorem 4.6 For all \\(\\delta \\in (0,1)\\), with probability at least \\(1-\\delta\\), we have: \\[ \\underset{\\mathfrak f \\in \\mathcal F}{\\operatorname{sup}} |R(\\mathfrak f) - R_n(\\mathfrak f)| \\leq 2 \\tilde{Rad}_n(\\mathcal F) + \\sqrt{\\frac{c \\operatorname{log}(\\frac{1}{\\delta})}{n}} \\] Proof. (Sketch of Proofs): For Theorem 4.5: We are interested in bounding \\(\\underset{\\mathfrak f \\in \\mathcal F}{\\operatorname{sup}} | R_n(\\mathfrak f) - R(\\mathfrak f) |\\). Given \\((x_1,y_1) \\cdots, (x_n,y_n)\\), \\(g((x_1,y_1) \\cdots, (x_n,y_n)):= \\underset{\\mathfrak f \\in \\mathcal F}{\\operatorname{sup}} | \\frac{1}{n} \\sum_{i=1}^n 1_{\\mathfrak f(x_i) \\neq y_i} - R(\\mathfrak f) |\\). We can check that the function \\(g\\) satisfies the condition for using McDiarmid’s Inequality: \\[ | g((x_1,y_1) \\cdots,(x_i,y_i),\\cdots, (x_n,y_n)) - g((x_1,y_1) \\cdots,(x&#39;_i,y&#39;_i),\\cdots, (x_n,y_n)) | \\leq \\frac{2}{n} \\] Because of this, we can conclude that \\(\\Big | \\underset{\\mathfrak f \\in \\mathcal F}{\\operatorname{sup}} | R_n(\\mathfrak f) - R(\\mathfrak f) | - E[\\underset{\\mathfrak f \\in \\mathcal F}{\\operatorname{sup}} | R_n(\\mathfrak f) - R(\\mathfrak f) |] \\Big | \\to 0\\) as \\(n \\to \\infty\\) a.s. To conclude, we would need to show that \\(E[\\underset{\\mathfrak f \\in \\mathcal F}{\\operatorname{sup}} | R_n(\\mathfrak f) - R(\\mathfrak f) |] \\leq 2 Rad_n(\\mathcal F)\\). \\[ R_n(\\mathfrak f) = \\frac{1}{n} \\sum_{i=1}^n 1_{\\mathfrak f(x_i) \\neq y_i} = \\frac{1}{2n} \\sum_{i=1}^n (1 - \\mathfrak f(x_i)y_i) \\] \\[ R(\\mathfrak f) = \\frac{1}{2} E[1-\\mathfrak f(X)Y] \\] \\[ |R_n(\\mathfrak f) - R(\\mathfrak f)| = \\frac{1}{2} \\Big|\\frac{1}{n} \\sum_{i=1}^n \\mathfrak f(x_i)y_i - E[\\mathfrak f(X)Y]\\Big| \\] For simplicity, assume \\(y_i = 1, i=1,\\cdots,n\\) and \\(Y=1\\), then we need to show that \\[ E\\Big[\\underset{\\mathfrak f \\in \\mathcal F}{\\operatorname{sup}} \\Big|\\frac{1}{n} \\sum_{i=1}^n \\mathfrak f(x_i) - E[\\mathfrak f(X)]\\Big|\\Big] \\leq 2 Rad_n(\\mathcal F) \\] \\[ \\begin{aligned} E_X\\Big[\\underset{\\mathfrak f \\in \\mathcal F}{\\operatorname{sup}} \\Big|\\frac{1}{n} \\sum_{i=1}^n \\mathfrak f(x_i) - E_{X&#39;}[\\mathfrak f(x_i&#39;)]\\Big|\\Big] &amp;= E_X\\Big[\\underset{\\mathfrak f \\in \\mathcal F}{\\operatorname{sup}} E_{X&#39;}\\Big|\\frac{1}{n} \\sum_{i=1}^n \\Big(\\mathfrak f(x_i) - \\mathfrak f(x_i&#39;)\\Big)\\Big|\\Big]\\\\ &amp;\\leq E_X E_{X&#39;}\\Big[\\underset{\\mathfrak f \\in \\mathcal F}{\\operatorname{sup}} \\Big|\\frac{1}{n} \\sum_{i=1}^n \\Big(\\mathfrak f(x_i) - \\mathfrak f(x_i&#39;)\\Big)\\Big|\\Big]\\\\ &amp;= E_{X,X&#39;}\\Big[\\underset{\\mathfrak f \\in \\mathcal F}{\\operatorname{sup}} \\Big|\\frac{1}{n} \\sum_{i=1}^n \\Big(\\mathfrak f(x_i) - \\mathfrak f(x_i&#39;)\\Big)\\Big|\\Big]\\\\ &amp;\\underset{\\text{show below}}{=} E_{X,X&#39;,\\sigma}\\Big[\\underset{\\mathfrak f \\in \\mathcal F}{\\operatorname{sup}} \\Big|\\frac{1}{n} \\sum_{i=1}^n \\sigma_i \\Big(\\mathfrak f(x_i) - \\mathfrak f(x_i&#39;)\\Big)\\Big|\\Big]\\\\ &amp;\\leq 2E_{X,\\sigma}\\Big[\\underset{\\mathfrak f \\in \\mathcal F}{\\operatorname{sup}} \\Big|\\frac{1}{n} \\sum_{i=1}^n \\sigma_i \\mathfrak f(x_i)\\Big|\\Big]\\\\ &amp;= 2 Rad_n(\\mathcal F) \\end{aligned} \\] For the equality mentioned above, whichever \\(\\sigma_i\\) is (\\(-1,1\\)), we have \\(\\sigma_i \\Big(\\mathfrak f(x_i) - \\mathfrak f(x_i&#39;)\\Big)\\) always have the same distribution. For Theorem 4.6: With high probability we have \\(\\underset{\\mathfrak f \\in \\mathcal F}{\\operatorname{sup}} |R(\\mathfrak f) - R_n(\\mathfrak f)| \\leq 2Rad_n(\\mathcal F) + O(\\sqrt{\\frac{1}{n}})\\). However, notice that we can find concentration bounds for \\(\\tilde{Rad}_n(\\mathcal F) - Rad_n(\\mathcal F)\\), as \\(E_X[\\tilde{Rad}_n(\\mathcal F)] = Rad_n(\\mathcal F)\\). Thus, \\(\\tilde{Rad}_n(\\mathcal F) - Rad_n(\\mathcal F) = \\tilde{Rad}_n(\\mathcal F) - E[\\tilde{Rad}_n(\\mathcal F)] := h(x_1, \\cdots, x_n)\\). Then, we can use McDiarmid’s Inequality if \\(|h(x_1, \\cdots, x_i, \\cdots, x_n) - h(x_1, \\cdots, x&#39;_i, \\cdots, x_n)| \\leq \\frac{2}{n}\\). How to Compute the Conditional Rademacher Average for a Given Family? How to estimate \\(\\tilde{Rad}_n(\\mathcal F)\\)? A: Use a Mote Carlo estimate. For \\(k = 1, \\cdots, K\\), we do the following: \\(\\sigma_1^k, \\cdots, \\sigma_n^k \\sim Rademacher\\) (\\(\\sigma_i^k \\in \\{-1, 1\\}\\)). Now consider: \\(\\underset{\\mathfrak f \\in \\mathcal F}{\\operatorname{sup}} | \\frac{1}{n} \\sum_{i=1}^n \\sigma_i^k \\mathfrak f(x_i) |\\), which is not so different from solving the problem: \\(\\underset{\\mathfrak f \\in \\mathcal F}{\\operatorname{max}} \\frac{1}{n} \\sum_{i=1}^n y_i \\mathfrak f(x_i)\\), but is as difficult as ERM. \\(\\tilde{Rad}_n(\\mathcal F)_k := \\underset{\\mathfrak f \\in \\mathcal F}{\\operatorname{sup}} | \\frac{1}{n} \\sum_{i=1}^n \\sigma_i^k \\mathfrak f(x_i) |\\). By doing this, we produce: \\(\\tilde{Rad}_n(\\mathcal F)_1, \\cdots, \\tilde{Rad}_n(\\mathcal F)_K\\). Therefore, by LLN, CLT, Concentration Inequalities, we can study how big \\(\\frac{1}{K} \\sum_{k=1}^K \\tilde{Rad}_n(\\mathcal F)_k - \\tilde{Rad}_n(\\mathcal F)\\) is (Concentration Ineqs as a function of \\(K\\)). "],["summary.html", "Chapter 5 Summary 5.1 Classification Problem 5.2 No Free Lunch Theorem", " Chapter 5 Summary 5.1 Classification Problem What are some statistical properties of two families of classifiers built from data? 5.1.1 Similarity Classifiers 5.1.2 Emprirical Risk Minimization 5.2 No Free Lunch Theorem “Pointwise Statement”: “Uniform Statement”: Example of Pointwise Statement vs Uniform Statement: No Free Lunch Theorem 1: Practical Corollary: No Free Lunch Theorem 2: Practical Corollary: Observation: we can not quantify the universal convergence rate. Conclusion: No magic classifier that suits every situation. "],["linear-classifiers.html", "Chapter 6 Linear Classifiers 6.1 LDA or QDA 6.2 Logistic Regression 6.3 Perceptrons and SVMs", " Chapter 6 Linear Classifiers \\(\\mathcal F = \\{\\text{all linear classifiers}\\}\\), \\(\\mathcal X = R^d\\), \\(\\mathcal Y = \\{-1,1\\}\\) or \\(\\{1,\\cdots,K\\}\\). Consider mainly on binary case. Let \\(\\beta \\in R^d\\) and \\(\\beta_0 \\in R\\), \\(\\mathcal H_{\\beta, \\beta_0} = \\{x\\in R^d: &lt;\\beta, x&gt; + \\beta_0 = 0\\}\\) (hyperplane), \\(\\mathcal H^+_{\\beta, \\beta_0} = \\{x\\in R^d: &lt;\\beta, x&gt; + \\beta_0 \\geq 0\\}\\) and \\(\\mathcal H^-_{\\beta, \\beta_0} = \\{x\\in R^d: &lt;\\beta, x&gt; + \\beta_0 &lt; 0\\}\\) (half plane). \\[ \\mathfrak f_{\\beta, \\beta_0}(x):=\\begin{cases}1 &amp; &lt;\\beta,x&gt; + \\beta_0 \\geq 0 (\\Leftrightarrow x \\in H^+_{\\beta,\\beta_0})\\\\- 1&amp; &lt;\\beta,x&gt; + \\beta_0 &lt; 0(\\Leftrightarrow x \\in H^-_{\\beta,\\beta_0})\\end{cases} \\] Question: How to find a linear classifier based on \\((x_i, y_i)\\), \\(i=1,\\cdots,n\\). A: Three different ways to tune \\(\\beta, \\beta_0\\) from data: LDA (linear discriminant analysis) or QDA (quadratic discriminant analysis), Logistic Regression, Perceptrons and SVMs. 6.1 LDA or QDA Let \\(\\mathcal Y = \\{1, \\cdots, K\\}\\), \\((X,Y) \\sim \\rho\\), where \\(P(Y=k) = \\omega_k, \\rho_{X|Y}(X | Y=k) = N(\\mu_k, \\Sigma_k)\\), we have: \\[ \\begin{aligned} \\mathfrak f_{Bayes}(x) &amp;= \\underset{k=1,\\cdots, K}{\\operatorname{argmax}} P(Y=k | X=x)\\\\ &amp;= \\underset{k=1,\\cdots, K}{\\operatorname{argmax}} \\frac{\\rho_{X|Y}(x | Y=k) \\cdot \\omega_k}{\\rho_X(x)}\\\\ &amp;= \\underset{k=1,\\cdots, K}{\\operatorname{argmax}} [\\rho_{X|Y}(x | Y=k) \\cdot \\omega_k]\\\\ &amp;= \\underset{k=1,\\cdots, K}{\\operatorname{argmax}} [log\\Big (\\rho_{X|Y}(x | Y=k)\\Big ) + log(\\omega_k)]\\\\ &amp;= \\underset{k=1,\\cdots, K}{\\operatorname{argmin}} [-log\\Big (\\frac{1}{(2\\pi)^{d/2} (det(\\Sigma_k))^{1/2}} \\Big ) + \\frac{1}{2} &lt;\\Sigma_k^{-1} (x-\\mu_k), (x-\\mu_k)&gt; - log(\\omega_k)]\\\\ &amp;:= \\underset{k=1,\\cdots, K}{\\operatorname{argmin}} \\delta_k(x) \\end{aligned} \\] Observation: \\(\\delta_k(x)\\) is quadratic and convex in \\(x\\). QDA: What if we only have \\((x_i, y_i)\\), \\(i=1,\\cdots,n\\)? We use the observations to estimate \\(\\mu_k, \\omega_k, \\Sigma_k\\), \\(k=1,\\cdots, K\\). Example 6.1 \\[ \\hat \\mu_k := \\frac{\\sum_{i ~s.t. ~y_i=k} x_i}{\\#\\{x_i ~s.t. ~y_i=k\\} ~(:= N_k)} \\] \\[ (\\hat \\Sigma_k)_{lm} := (\\frac{1}{N_k} \\sum_{i ~s.t. ~y_i=k} x_{il}x_{im} - \\hat \\mu_{kl} \\hat \\mu_{km}), \\text{ where } l=1,\\cdots,d, ~m=1,\\cdots,d. \\] \\[ \\hat \\omega_k = \\frac{N_k}{n} \\] \\[ \\hat \\delta_k(x) \\text{ same as } \\delta_k \\text{ but with } \\hat{} \\text{ everywhere} \\] LDA: What if we had assumed \\(\\Sigma_1 = \\Sigma_2 = \\cdots = \\Sigma_K = \\Sigma\\)? \\[ \\begin{aligned} \\mathfrak f(x) &amp;= \\underset{k=1,\\cdots, K}{\\operatorname{argmin}} [\\frac{1}{2} &lt;\\Sigma^{-1}x, x&gt; + &lt;\\Sigma^{-1}x, \\mu_k&gt; + \\frac{1}{2} &lt;\\Sigma^{-1}\\mu_k, \\mu_k&gt; - log(\\omega_k)]\\\\ &amp;= \\underset{k=1,\\cdots, K}{\\operatorname{argmin}} [&lt;\\Sigma^{-1}x, \\mu_k&gt; + \\frac{1}{2} &lt;\\Sigma^{-1}\\mu_k, \\mu_k&gt; - log(\\omega_k)]\\\\ &amp;:= \\underset{k=1,\\cdots, K}{\\operatorname{argmin}} l_k(x), ~(l_k(x) \\text{ is linear}) \\end{aligned} \\] We can estimate \\(\\mu_k ,\\omega_k\\) by \\(\\hat \\mu_k ,\\hat \\omega_k\\), and \\(\\Sigma\\) with the full data set. 6.2 Logistic Regression Let \\(\\mathcal Y = \\{1, \\cdots, K\\}\\), \\(\\vec \\beta_k \\in R^d\\), \\(\\beta_{0k} \\in R\\), and \\((X,Y)\\) satisfies: \\(P(Y=k | X=x) = \\frac{exp(&lt;x,\\vec \\beta_k&gt; + \\beta_{0k})}{1 + \\sum_{l=1}^{K-1} exp(&lt;x,\\vec \\beta_l&gt; + \\beta_{0l})}\\), \\(P(Y=K | X=x) = \\frac{1}{1 + \\sum_{l=1}^{K-1} exp(&lt;x,\\vec \\beta_l&gt; + \\beta_{0l})}\\), where \\(k=1,\\cdots,K-1\\). Let \\(\\varphi_k(x) := exp(&lt;x,\\vec \\beta_k&gt; + \\beta_{0k})\\) and \\(\\varphi_K(x):=1\\), where \\(k=1,\\cdots,K-1\\). Then we have: \\[ \\begin{aligned} \\mathfrak f_{Bayes} (x) &amp;= \\underset{k=1,\\cdots, K}{\\operatorname{argmax}} P(Y=k | X=x)\\\\ &amp;= \\underset{k=1,\\cdots, K}{\\operatorname{argmax}} \\varphi_k(x)\\\\ &amp;= \\underset{k=1,\\cdots, K}{\\operatorname{argmax}} log(\\varphi_k(x)) \\end{aligned} \\] What if we only have observed \\((x_i, y_i)\\), \\(i=1,\\cdots,n\\)? We use the observations to estimate the parameters. Example 6.2 (MLE) Given the data, find the best parameters (the ones maximizing the likelihood of the observations), i.e. \\[ \\{(\\vec \\beta_k^*, \\beta_{0k}^*)\\} = \\underset{\\{(\\vec \\beta_k, \\beta_{0k})\\}_{k=1,\\cdots,K-1}}{\\operatorname{max}} \\prod_{i=1}^n P(Y = y_i | X = x_i) \\] 6.3 Perceptrons and SVMs Let \\(\\mathcal Y = \\{-1, 1\\}\\), \\((x_i, y_i)_{i=1,\\cdots,n}\\), \\((\\vec \\beta, \\beta_0)\\), \\(\\mathfrak f_{\\beta, \\beta_0}(x):=\\begin{cases}1 &amp; &lt;\\beta,x&gt; + \\beta_0 \\geq 0 (\\Leftrightarrow x \\in H^+_{\\beta,\\beta_0})\\\\- 1&amp; &lt;\\beta,x&gt; + \\beta_0 &lt; 0(\\Leftrightarrow x \\in H^-_{\\beta,\\beta_0})\\end{cases}\\), \\(\\sigma(\\vec \\beta, \\beta_0) := \\sum_{i \\in \\mathcal M_{\\vec \\beta, \\beta_0}} dist(x_i, \\mathcal H_{\\vec \\beta, \\beta_0})\\), where \\(\\mathcal M_{\\vec \\beta, \\beta_0} = \\{i \\text{ s.t. } \\mathfrak f_{\\vec \\beta, \\beta_0} (x_i) \\neq y_i\\}\\) Perceptrons: Let \\((\\vec \\beta^*, \\beta_0^*) := \\underset{(\\vec \\beta, \\beta_{0})}{\\operatorname{min}} \\sigma(\\vec \\beta, \\beta_0)\\), then the perceptron classifier is \\(\\mathfrak f_{\\vec \\beta^*, \\beta_0^*} (x)\\). There exist many solutions of perceptron problems but some hyperplanes seem to be more robust: Example 6.3 Hyperplane 2 seems to be more robust. SVMs: Let’s suppose that \\((x_i, y_i)_{i=1,\\cdots,n}\\) is linearly separable (for motivation for now). Then there exists at least one \\(\\vec \\beta, \\beta_0\\) s.t. \\(\\mathcal M_{\\vec \\beta, \\beta_0} = \\emptyset\\). What we want is to find \\(\\underset{(\\vec \\beta, \\beta_{0})}{\\operatorname{max}} Margin(\\vec \\beta, \\beta_0)\\) s.t. \\(\\mathcal M_{\\vec \\beta, \\beta_0} = \\emptyset\\), where \\(Margin(\\vec \\beta, \\beta_0):= min\\{C^+_{\\vec \\beta, \\beta_0}, C^-_{\\vec \\beta, \\beta_0}\\}\\), \\(C^+_{\\vec \\beta, \\beta_0} = \\underset{x_i \\text{ s.t. } y_i = 1}{\\operatorname{min}} dist(x_i, \\mathcal H_{\\vec \\beta, \\beta_0})\\) and \\(C^-_{\\vec \\beta, \\beta_0} = \\underset{x_i \\text{ s.t. } y_i = -1}{\\operatorname{min}} dist(x_i, \\mathcal H_{\\vec \\beta, \\beta_0})\\). "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
