# Uncertainty Quantification
Imagine there is an unknown quantity \(u\) that we can't observe directly. However, we may obtain a collection of observations \(Y = (y_i, \cdots, y_p) \in \mathcal R^p\). Then the **Forward Problem** is \(\underset{\text{unknown}}{u \in Z} \to \underset{\text{observed}}{Y}\).

In a sense, when we talk about science, we are talking about use \(Y\) to learn about \(u\). In practice, there are at least two "sources" of uncertainty associated to the picture: \(u \to Y\):

1. \(u\) is unknown.

2. Observations are usually contaminated by some sort of noise so that in general \(Y\) is not simply a function of the unknown \(u\). In statistics, we may model the "likelihood" or "probability" of observing \(Y\) given a certain value of \(u\). This quantifies our uncertainty of the possible values \(Y\) given the unknown \(u\) through the probability mass function: \(P(Y = y, | u)\) or through a density function: \(P(Y \in C | u) = \int_C p(y | u) dy\).

:::{.example #ber}
Let \(u \in (0,1)\) be the probability that the outcome of a certain biased coin flip is H. Suppose that this coin is flipped \(p\) times and we get \(y_i = \begin{cases}1 &i\text{-th is H}\\0 & i\text{-th is T}\end{cases}\). 

In this case, the likelihood is 

$$
P(Y = y | u) = u^{\sum_{i=1}^p y_i} (1-u)^{p - \sum_{i=1}^p y_i}, ~y_i \in \{0,1\}
$$
:::

:::{.example #gau}
- Regression: \(u: \mathcal X \to \mathcal R\) (Hidden regression function). \(y_i = u(x_i) + \varepsilon_i\), \(\varepsilon_i \sim N(0, \sigma^2)\).  
$$
p(y|u) = \frac{1}{(\sqrt{2 \pi \sigma^2})^p} exp(-\frac{||y - (u(x_1), \cdots, u(x_n)||^2}{2\sigma^2})
$$

- Classification with logistic model: Given \(u: \mathcal X \to \mathcal R\), define: \(q_i = \frac{exp(u(x_i))}{1+exp(u(x_i))}\) for \(x_1, \cdots, x_p\). Then, \(y_i = \begin{cases}1 &\text{with prob } q_i\\0 & \text{with prob } 1-q_i\end{cases}\). Thus,  
$$
P(y | u) = \prod_{i=1}^p q_i^{y_i} (1- q_i)^{1-y_i} = \prod_{i=1}^p \frac{exp(y_iu(x_i))}{1+exp(u(x_i))}
$$
::: 

:::{.example #DE name="Density Estimation"}
Let \(\mathcal X = \mathcal R^d\) and suppose that \(u: \mathcal X \to \mathcal R\) is an unknown density function (\(u(x) \geq 0\), \(\forall x\), and \(\int_{\mathcal R^d} u(x) dx = 1\)), \(y_1, \cdots, y_p \underset{i.i.d}{\sim} u\). Thus, the likelihood of \(Y=(y_1, \cdots, y_p)\) is:  
$$
p(y|u) = u(y_1) \cdots u(y_p)
$$
:::

So far we have talked about the distribution of \(Y\) given \(u\) (Forward Problem). This models the uncertainty of our "measurement" if we had access to \(u\). However, how do we learn \(u\) from \(Y\) (Inverse Problem)? Moreover, how do we quantify the uncertainty of the unknown \(u\) before observing \(Y\), and after observing \(Y\)?

## Bayes Perspective

Bayes Rule: \(p(u | y) \propto p(y | u) \pi(u)\). For the moment, we consider the case where \(u \in \mathcal R^d\). Suppose \(\pi(u)\) is then interpreted as a density in \(\mathcal R^d\). The posterior is usually also a density in \(\mathcal R^d\).

:::{.example name="Example \@ref(exm:ber) Continued"}
Let \(u \in (0,1)\), the likelihood is \(Bernoulli(u):\)

$$
P(Y = y | u) = u^{\sum_{i=1}^p y_i} (1-u)^{p - \sum_{i=1}^p y_i}, ~y_i \in \{0,1\},
$$

the prior is \(Beta(\alpha, \beta)\):

$$
\pi(u) = \frac{u^{\alpha-1}(1-u)^{\beta-1}}{\Gamma(\alpha, \beta)}, ~\alpha, \beta >0.
$$

Then the posterior is 

$$
p(u | y) \propto p(y |u) \pi(u) \propto u^{\sum_{i=1}^p y_i + \alpha - 1} (1-u)^{p - \sum_{i=1}^p y_i + \beta - 1},
$$

that is, given \(Y=y\), \(u\) is \(Beta(\sum_{i=1}^p y_i + \alpha, p - \sum_{i=1}^p y_i + \beta)\)
:::

:::{.example #gaucon name="Example \@ref(exm:gau) Continued"}
Let \(u \in \mathcal R^d\) and \(x_1, \cdots, x_p \in \mathcal R^d\), the likelihood is:

$$
p(y|u) = \frac{1}{(\sqrt{2 \pi \sigma^2})^p} exp(-\frac{||y - (u(x_1), \cdots, u(x_n)||^2}{2\sigma^2}),
$$

the prior is 

$$
\pi(u) = \frac{1}{(\sqrt{2 \pi \lambda^{-1}})^p} exp(-\frac{\lambda}{2} ||u||^2_{\mathcal R^d}), ~i.e. ~ u \sim N(\vec 0, \frac{1}{\lambda} I).
$$

Let \(X = (x_1, \cdots, x_p)^T_{p \times d}\). Then the posterior is 

$$
\begin{aligned}
p(u | y) &\propto p(y |u) \pi(u) \\
&\propto exp \Big(<\frac{X^Ty}{\sigma^2}, u> - \frac{1}{2} <(\lambda I + \frac{X^TX}{\sigma^2})u, u>\Big)\\
&= N(\mu, \Sigma),
\end{aligned}
$$

where \(\mu = \frac{1}{\sigma^2} (\lambda I + \frac{1}{\sigma^2} (X^TX))^{-1} X^Ty\) and \(\Sigma= (\lambda I + \frac{1}{\sigma^2} (X^TX))^{-1}\).
:::


With the posterior, we can then compute the following:

1. Posterior Mean:

$$
\begin{aligned}
\hat u_{PM} = E[u_i | y] &= \frac{\int_{\mathcal R^d} u_i p(y | u) \pi(u) du_1 \cdots du_d}{\int_{\mathcal R^d} p(y | u) \pi(u) du_1 \cdots du_d}\\
&= \frac{\int_{\mathcal R^d} u_i p(y | u) \pi(u) du_1 \cdots du_d}{Z(y)}
\end{aligned}
$$

where \(Z(y)\) is the normalization constant. 

Then, based on the observations (and model), we estimate the i-th coordinate of the unknown as \(E[u_i | y]\).

We could also estimate \(u_i^2 cos(u_j)\) with: \(E[u_i^2 cos(u_j) | y] = \frac{\int_{\mathcal R^d} u_i^2cos(u_j) p(y | u) \pi(u) du_1 \cdots du_d}{Z(y)}\)

2. Posterior Covariance: \(Cov(u_i, u_j | y)\) or \(Var(u_i|y) = E[u_i^2 | y] - (E[u|y])^2\). A measure of how certain we are about the estimation of \(u_i\).

3. Map (Maximum a posterior):

$$
\begin{aligned}
u^* &= \underset{u}{\operatorname{arg max}} \pi(u) p(y | u)\\
&= \underset{u}{\operatorname{arg max}} log(\pi(u)) + log(p(y | u))\\
&= \underset{u}{\operatorname{arg min}} -log(\pi(u)) - log(p(y | u))
\end{aligned}
$$

Both 1 and 2 are based on being able to take expectation w.r.t. posterior. 3 on the other hand, is not related to expectation but rather to optimization.

:::{.example #gauconcon name="Example \@ref(exm:gaucon) Continued"}
We have:

- \(E[u_i |y] = \mu_i\)

- \(Cov(u_iu_j | y) = \Sigma_{ij}\)

- The Map is determined by:  
$$
\begin{aligned}
u^* &= \underset{u}{\operatorname{arg min}} -log(p(u | y))\\
&= \underset{u}{\operatorname{arg min}} -log(\pi(u)) - log(p(y | u))\\
&= \underset{u}{\operatorname{arg min}} \frac{\lambda}{2} ||u||^2 + \frac{1}{\sigma^2} \sum_{j=1}^p (y_i - <u, x_i>)^2,
\end{aligned}
$$

which is just the ridge regression.
:::

:::{.remark}
$$
u^* = \mu
$$

This can be seen by direct optimization or by noticing that the Map of a Gaussian random vector coincides with its mean vector.

The posterior can be interpreted as a different kind of regularization:

$$
p(u | y) \propto \underset{\text{Fidality}}{p(y | u)} ~\underset{\text{Regularizer}}{\pi(u)}
$$
:::

Back to **Example \@ref(exm:gauconcon)**, when \(u | y\) is \(N(\mu, \Sigma)\), we have formulas for \(E[u_i | y]\) and \(Cov(u_i, u_j)\). However, something like \(E[u_1cos(u_2) exp(u_3) | y]\) would be quite impossible to compute. Nevertheless, we can use Monte-Carlo to approximate this. The idea is that we know what the posterior is. Thus, we can try to sample \(u^1, \cdots, u^K \sim N_d(\mu, \Sigma)\). Then consider the empirical average: \(\frac{1}{K} \sum{j=1}^K u_1^j cos(u_2^j) exp(u_3^j)\). That is, if we can sample from the posterior, we can numerically approximate \(E[G(u) | y] \approx \frac{1}{K} \sum_{j=1}^K G(u^j)\), where \(u^1, \cdots, u^K \underset{i.i.d}{\sim} Posterior\).

If it is difficult to sample from the posterior, we can use MCMC (Monte Carlo Markov Chain).























